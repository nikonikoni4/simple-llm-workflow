# æ‰§è¡Œå™¨å®šä¹‰ V2
# æ”¯æŒå¤šçº¿ç¨‹ Context å’Œ 4 ç§èŠ‚ç‚¹ç±»å‹åˆ†å‘

from data_driving_schemas import (
    Context, NodeDefinition, ExecutionPlan, NodeType
)
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

from typing import Callable
import logging
logger = logging.getLogger(__name__)
class Executor:
    """
    æ•°æ®é©±åŠ¨æ‰§è¡Œå™¨ V2
    
    æ”¯æŒç‰¹æ€§:
    - å¤šçº¿ç¨‹ Context æ¶ˆæ¯éš”ç¦»
    - 4 ç§èŠ‚ç‚¹ç±»å‹åˆ†å‘æ‰§è¡Œ (llm_auto, tool, query, planning)
    - data_out æœºåˆ¶: å­çº¿ç¨‹å‘çˆ¶çº¿ç¨‹è¾“å‡ºç»“æœ
    """
    

    def __init__(
        self,
        plan: ExecutionPlan,
        user_message: str,
        main_thread_id: str = "main",
        tools_map: dict[str, Callable] | None = None,
        default_tools_limit: int | None = 1,
        llm_factory: Callable[[], any] | None = None
    ):
        """
        åˆå§‹åŒ–æ‰§è¡Œå™¨

        Args:
            plan: æ‰§è¡Œè®¡åˆ’
            user_message: ç”¨æˆ·æ¶ˆæ¯
            main_thread_id: ä¸»çº¿ç¨‹ ID
            tools_map: å·¥å…·æ˜ å°„ {tool_name: callable}
            default_tools_limit: é»˜è®¤å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼ˆæ¯ä¸ªå·¥å…·çš„é»˜è®¤è°ƒç”¨æ¬¡æ•°ï¼‰ï¼ŒNone è¡¨ç¤ºæ— é™åˆ¶
            llm_factory: LLM å·¥å‚å‡½æ•°ï¼Œç”¨äºåˆ›å»º LLM å®ä¾‹ã€‚å¦‚æœä¸æä¾›ï¼Œéœ€è¦è‡ªè¡Œè®¾ç½®é»˜è®¤å·¥å‚
        """
        self.plan = plan
        self.main_thread_id = main_thread_id
        self.llm_factory = llm_factory

        # æ–°çš„å¤šçº¿ç¨‹ Context ç»“æ„
        self.context: Context = {
            "messages": {
                main_thread_id: [HumanMessage(content=user_message)]
            },
            "data_out": {},
        }

        # å·¥å…·æ˜ å°„
        if tools_map is None:
            tools_map = {}
            logger.warning("æœªæä¾›å·¥å…·æ˜ å°„")
        self.tools_map = tools_map

        # é»˜è®¤å·¥å…·ä½¿ç”¨é™åˆ¶ï¼ˆå½“èŠ‚ç‚¹æœªè®¾ç½® tools_limit æ—¶ä½¿ç”¨ï¼‰
        self._default_tools_limit = default_tools_limit
        self.tools_usage_limit = {}
        
        # tokens ä½¿ç”¨ç»Ÿè®¡
        self.tokens_usage = {
            'input_tokens': 0,
            'output_tokens': 0,
            'total_tokens': 0
        }
        
        # èŠ‚ç‚¹ç±»å‹ -> å¤„ç†å‡½æ•° æ˜ å°„
        self._node_handlers: dict[NodeType, Callable[[NodeDefinition], str]] = {
            "llm-first": self._execute_llm_first_node,
            "tool-first": self._execute_tool_first_node,
            "planning": self._execute_planning_node,
        }
        self.role_map = {
            "llm-first": "assistant",
            "tool-first": "tool",
            "planning": "assistant"
        }


    # =========================================================================
    # Context è¾…åŠ©æ–¹æ³•
    # =========================================================================
    def _get_thread_messages(self, thread_id: str) -> list:
        """è·å–æŒ‡å®šçº¿ç¨‹çš„æ¶ˆæ¯åˆ—è¡¨"""
        return self.context["messages"].get(thread_id, [])

    def _add_message_to_thread(self, thread_id: str, message) -> None:
        """æ·»åŠ æ¶ˆæ¯åˆ°æŒ‡å®šçº¿ç¨‹"""
        if thread_id not in self.context["messages"]:
            raise ValueError(f"çº¿ç¨‹ {thread_id} ä¸å­˜åœ¨")
        self.context["messages"][thread_id].append(message)

    def _create_thread(self, thread_id: str, node: NodeDefinition | None = None) -> None:
        """
        åˆ›å»ºæ–°çº¿ç¨‹ï¼Œå¹¶æ ¹æ® node çš„ data_in é…ç½®æ³¨å…¥åˆå§‹æ¶ˆæ¯
        
        Args:
            thread_id: æ–°çº¿ç¨‹ID
            node: èŠ‚ç‚¹å®šä¹‰ï¼Œç”¨äºè·å– data_in é…ç½®
        """
        if thread_id in self.context["messages"]:
            return  # çº¿ç¨‹å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        
        self.context["messages"][thread_id] = []
        # å¤„ç† data_inï¼šæ³¨å…¥åˆå§‹æ¶ˆæ¯åˆ°æ–°çº¿ç¨‹
        if node is not None:
            # ç¡®å®šæ•°æ®æ¥æºçº¿ç¨‹ï¼šä¼˜å…ˆä½¿ç”¨ data_in_threadï¼Œå¦åˆ™é»˜è®¤ä¸º main
            source_thread = node.data_in_thread or self.main_thread_id
            if not node.data_in_thread:
                logger.warning(f"    âš ï¸  data_in: èŠ‚ç‚¹ '{node.node_name}' æ²¡æœ‰æŒ‡å®š data_in_threadï¼Œä½¿ç”¨é»˜è®¤çš„ main çº¿ç¨‹")
            if source_thread and source_thread in self.context["messages"]:
                source_msgs = self.context["messages"][source_thread]
                
                # æ£€æŸ¥æºçº¿ç¨‹æ˜¯å¦æœ‰æ•°æ®
                if source_msgs:
                    if node.data_in_slice:
                        # ä½¿ç”¨æŒ‡å®šçš„åˆ‡ç‰‡èŒƒå›´
                        start, end = node.data_in_slice
                        injected = source_msgs[start:end]
                    else:
                        # é»˜è®¤ï¼šå–æœ€åä¸€æ¡æ¶ˆæ¯
                        injected = [source_msgs[-1]]
                    
                    # æ³¨å…¥æ¶ˆæ¯åˆ°æ–°çº¿ç¨‹
                    if injected:
                        self.context["messages"][thread_id].extend(injected)
                        logger.debug(f"    â†’ data_in: ä» '{source_thread}' æ³¨å…¥ {len(injected)} æ¡æ¶ˆæ¯åˆ° '{thread_id}'")

    def _set_data_out(self, thread_id: str, node_type: str, description: str, content: str) -> None:
        """è®¾ç½®çº¿ç¨‹çš„è¾“å‡ºæ•°æ®"""
        self.context["data_out"][thread_id] = {
            "role": self.role_map[node_type],
            "content": f"{description}{content}" if description else content
        }

    def _merge_data_out(self, child_thread_id: str, target_thread_id: str) -> None:
        """
        å°†å­çº¿ç¨‹çš„ data_out åˆå¹¶åˆ°ç›®æ ‡çº¿ç¨‹çš„ messages
        
        Args:
            child_thread_id: å­çº¿ç¨‹IDï¼ˆæ•°æ®æ¥æºï¼‰
            target_thread_id: ç›®æ ‡çº¿ç¨‹IDï¼ˆç”±èŠ‚ç‚¹çš„ data_out_thread å†³å®šï¼‰
        """
        if child_thread_id not in self.context["data_out"]:
            return
        
        if target_thread_id and target_thread_id in self.context["messages"]:
            data = self.context["data_out"][child_thread_id]
            self._add_message_to_thread(target_thread_id, AIMessage(content=data["content"]))
            logger.debug(f"    â†’ data_out: ä» '{child_thread_id}' åˆå¹¶åˆ° '{target_thread_id}'")

    # =========================================================================
    # å·¥å…·ç®¡ç†æ–¹æ³•
    # =========================================================================
    def reset_tools_limit(self, node: NodeDefinition | None = None):
        """
        é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶

        Args:
            node: å½“å‰æ‰§è¡Œçš„èŠ‚ç‚¹ã€‚å¦‚æœèŠ‚ç‚¹è®¾ç½®äº† tools_limitï¼Œåˆ™ä¸é»˜è®¤é™åˆ¶åˆå¹¶ï¼›
                  èŠ‚ç‚¹çš„é™åˆ¶ä¼˜å…ˆçº§é«˜äºé»˜è®¤é™åˆ¶ã€‚
        """
        self.tools_usage_limit = {}

        # è·å–å½“å‰èŠ‚ç‚¹ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
        tools_to_limit = set()
        if node and node.tools:
            tools_to_limit.update(node.tools)

        # åº”ç”¨é»˜è®¤é™åˆ¶åˆ°æ‰€æœ‰ç›¸å…³å·¥å…·
        if self._default_tools_limit is not None:
            for tool in tools_to_limit:
                self.tools_usage_limit[tool] = self._default_tools_limit

        # å¦‚æœèŠ‚ç‚¹æœ‰å•ç‹¬çš„ tools_limitï¼Œè¦†ç›–é»˜è®¤å€¼ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
        if node and node.tools_limit:
            self.tools_usage_limit.update(node.tools_limit)
    
    def reset_tokens_usage(self):
        """é‡ç½® tokens ä½¿ç”¨ç»Ÿè®¡"""
        self.tokens_usage = {
            'input_tokens': 0,
            'output_tokens': 0,
            'total_tokens': 0
        }
    
    def _accumulate_tokens(self, result) -> None:
        """ç´¯åŠ  tokens ä½¿ç”¨é‡"""
        if not result:
            logger.debug("    âš ï¸  _accumulate_tokens: result ä¸ºç©ºï¼Œè·³è¿‡ç»Ÿè®¡")
            return

        tokens_added = False

        # å°è¯•ä» response_metadata è·å– token usage
        if hasattr(result, 'response_metadata') and 'token_usage' in result.response_metadata:
            token_usage = result.response_metadata['token_usage']
            input_tokens = token_usage.get('input_tokens', 0)
            output_tokens = token_usage.get('output_tokens', 0)
            total_tokens = token_usage.get('total_tokens', 0)

            self.tokens_usage['input_tokens'] += input_tokens
            self.tokens_usage['output_tokens'] += output_tokens
            self.tokens_usage['total_tokens'] += total_tokens
            tokens_added = True
            logger.debug(f"    ğŸ“Š Token ç»Ÿè®¡ (response_metadata): input={input_tokens}, output={output_tokens}, total={total_tokens}")

        # å°è¯•ç›´æ¥ä» result è·å– token usageï¼ˆæŸäº› LLM å®ç°ï¼‰
        elif hasattr(result, 'token_usage'):
            token_usage = result.token_usage
            input_tokens = token_usage.get('input_tokens', 0)
            output_tokens = token_usage.get('output_tokens', 0)
            total_tokens = token_usage.get('total_tokens', 0)

            self.tokens_usage['input_tokens'] += input_tokens
            self.tokens_usage['output_tokens'] += output_tokens
            self.tokens_usage['total_tokens'] += total_tokens
            tokens_added = True
            logger.debug(f"    ğŸ“Š Token ç»Ÿè®¡ (token_usage): input={input_tokens}, output={output_tokens}, total={total_tokens}")

        # å°è¯•ä» usage_metadata è·å–ï¼ˆOpenAI æ–°ç‰ˆæ ¼å¼ï¼‰
        elif hasattr(result, 'usage_metadata'):
            usage = result.usage_metadata
            input_tokens = usage.get('input_tokens', 0)
            output_tokens = usage.get('output_tokens', 0)
            total_tokens = usage.get('total_tokens', 0)

            self.tokens_usage['input_tokens'] += input_tokens
            self.tokens_usage['output_tokens'] += output_tokens
            self.tokens_usage['total_tokens'] += total_tokens
            tokens_added = True
            logger.debug(f"    ğŸ“Š Token ç»Ÿè®¡ (usage_metadata): input={input_tokens}, output={output_tokens}, total={total_tokens}")

        if not tokens_added:
            logger.warning(f"    âš ï¸  æ— æ³•ä» LLM å“åº”ä¸­è·å– token ç»Ÿè®¡ä¿¡æ¯")
            logger.debug(f"    ğŸ“‹ result ç±»å‹: {type(result)}, å±æ€§: {dir(result)}")

    def _validate_tools(self, tools: list[str] | None):
        """éªŒè¯å·¥å…·æ˜¯å¦å­˜åœ¨"""
        if not tools:
            return
        for tool in tools:
            if tool not in self.tools_map:
                raise ValueError(f"å·¥å…· {tool} ä¸å­˜åœ¨ï¼Œå¯ç”¨å·¥å…·: {list(self.tools_map.keys())}")

    def _can_use_tool(self, tool_name: str) -> bool:
        """åˆ¤æ–­æŒ‡å®šå·¥å…·æ˜¯å¦è¿˜èƒ½è°ƒç”¨ï¼ˆæœªå£°æ˜çš„å·¥å…·é»˜è®¤æœ‰ DEFAULT_TOOL_USAGE_COUNT æ¬¡è°ƒç”¨æœºä¼šï¼‰"""
        return self.tools_usage_limit.get(tool_name, self._default_tools_limit) > 0
    
    def _consume_tool_usage(self, tool_name: str) -> None:
        """æ¶ˆè€—ä¸€æ¬¡å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼ˆæœªå£°æ˜çš„å·¥å…·ä¼šè¢«åˆå§‹åŒ–åå†æ¶ˆè€—ï¼‰"""
        if tool_name not in self.tools_usage_limit:
            # æœªå£°æ˜çš„å·¥å…·ï¼Œåˆå§‹åŒ–ä¸ºé»˜è®¤æ¬¡æ•°
            self.tools_usage_limit[tool_name] = self._default_tools_limit
        self.tools_usage_limit[tool_name] -= 1

    def _has_available_tools(self, tools: list[str] | None) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¯ç”¨çš„å·¥å…·è°ƒç”¨æ¬¡æ•°"""
        if not tools:
            return False
        return any(self._can_use_tool(tool) for tool in tools)

    def _tools_limit_prompt(self, tools: list[str] | None) -> str:
        """ç”Ÿæˆå·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶çš„ prompt"""
        if not tools:
            return ""
        lines = []
        for tool in tools:
            remaining = self.tools_usage_limit.get(tool, 0)
            lines.append(f"å·¥å…· {tool} å¯ä»¥è°ƒç”¨ {remaining} æ¬¡")
        return "\n".join(lines)

    def _create_llm_with_tools(self, tools: list[str] | None):
        """åˆ›å»º LLMï¼Œå¦‚æœæœ‰å·¥å…·åˆ™ç»‘å®š"""
        if self.llm_factory is None:
            raise ValueError("å¿…é¡»æä¾› llm_factory æ¥åˆ›å»º LLM å®ä¾‹")

        llm = self.llm_factory()
        if tools:
            tool_objects = [self.tools_map[t] for t in tools]
            llm = llm.bind_tools(tool_objects)
        return llm

    # =========================================================================
    # Prompt æ„å»º
    # =========================================================================
    def get_history(self, thread_id: str) -> str:
        """è¿”å›æŒ‡å®šçº¿ç¨‹çš„æ ¼å¼åŒ–å†å²æ¶ˆæ¯å­—ç¬¦ä¸²"""
        result = []
        messages = self._get_thread_messages(thread_id)
        for message in messages:
            if isinstance(message, HumanMessage):
                result.append(f"user: {message.content}")
            elif isinstance(message, ToolMessage):
                result.append(f"tool: {message.content}")
            elif isinstance(message, AIMessage):
                # å¦‚æœæœ‰ tool_callsï¼Œéœ€è¦æ ¼å¼åŒ–è¾“å‡º
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    tool_calls_str = ", ".join([
                        f"{tc.get('name', 'unknown')}({tc.get('args', {})})" 
                        for tc in message.tool_calls
                    ])
                    result.append(f"assistant: [è°ƒç”¨å·¥å…·: {tool_calls_str}]")
                    if message.content:
                        result.append(f"assistant: {message.content}")
                else:
                    result.append(f"assistant: {message.content}")
        return "\n".join(result) if result else ""

    def _get_prompt(self, node: NodeDefinition) -> str:
        """æ„å»ºèŠ‚ç‚¹çš„ prompt"""
        return f"""
# å†å²æ¶ˆæ¯
{self.get_history(node.thread_id)}
# ä½ éœ€è¦æŒ‰ç…§ä¸‹é¢è¦æ±‚å®Œæˆä»»åŠ¡ï¼š
{node.task_prompt}
"""

    # =========================================================================
    # å·¥å…·æ‰§è¡Œ
    # =========================================================================
    def _execute_tool_call_for_thread(self, tool_call: dict, thread_id: str) -> tuple[bool, str | None]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶å°†ç»“æœæ·»åŠ åˆ°æŒ‡å®šçº¿ç¨‹"""
        tool_name = tool_call.get("name", "")
        tool_args = tool_call.get("args", {})
        tool_id = tool_call.get("id", "")
        
        if tool_name not in self.tools_map:
            error_msg = f"æœªçŸ¥å·¥å…·: {tool_name}ï¼Œå¯ç”¨å·¥å…·: {list(self.tools_map.keys())}"
            logger.info(f"    âœ— {error_msg}")
            return False, error_msg
        
        if not self._can_use_tool(tool_name):
            error_msg = f"å·¥å…· {tool_name} è°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œ"
            logger.info(f"    âœ— {error_msg}")
            self._add_message_to_thread(thread_id, ToolMessage(content=error_msg, tool_call_id=tool_id))
            return False, error_msg
        
        logger.info(f"    - æ‰§è¡Œå·¥å…·: {tool_name}, args: {tool_args}")
        tool_result = self.tools_map[tool_name].invoke(tool_args)
        self._consume_tool_usage(tool_name)
        logger.info(f"    - å·¥å…· {tool_name} å‰©ä½™è°ƒç”¨æ¬¡æ•°: {self.tools_usage_limit[tool_name]}")
        
        self._add_message_to_thread(thread_id, ToolMessage(content=str(tool_result), tool_call_id=tool_id))
        return True, str(tool_result)

    # =========================================================================
    # èŠ‚ç‚¹å¤„ç†å™¨
    # =========================================================================
    
    def _llm_tool_loop(self, node: NodeDefinition, llm) -> str:
        """
        LLM å·¥å…·è°ƒç”¨å¾ªç¯
        
        ä½¿ç”¨ messages åˆ—è¡¨è°ƒç”¨ LLMï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨ç›´åˆ° LLM è¿”å›æœ€ç»ˆç»“æœ
        """
        # æ·»åŠ ä»»åŠ¡ prompt åˆ°çº¿ç¨‹
        tools_limit_prompt = self._tools_limit_prompt(node.tools)
        initial_task_prompt = f"""å·¥å…·å¯è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼Œè¯·åˆç†å®‰æ’å·¥å…·è°ƒç”¨:
{tools_limit_prompt}
ä½ éœ€è¦æŒ‰ç…§ä¸‹é¢è¦æ±‚å®Œæˆä»»åŠ¡ï¼š
{node.task_prompt}"""
        self._add_message_to_thread(node.thread_id, HumanMessage(content=initial_task_prompt))
        
        result = None
        round_count = 0
        while True:
            round_count += 1
            logger.debug(f"[DEBUG] ç¬¬ {round_count} è½®å¾ªç¯")
            
            messages = self._get_thread_messages(node.thread_id)
            result = llm.invoke(messages)
            self._accumulate_tokens(result)
            self._add_message_to_thread(node.thread_id, result)
            
            # æ—  tool_callsï¼Œç»“æŸ
            if not (hasattr(result, 'tool_calls') and result.tool_calls):
                logger.debug(f"    â†’ LLM è¿”å›æœ€ç»ˆç»“æœï¼ˆæ—  tool_callsï¼‰")
                break
            
            # æ‰§è¡Œå·¥å…·
            logger.debug(f"    â†’ LLM è¯·æ±‚è°ƒç”¨ {len(result.tool_calls)} ä¸ªå·¥å…·")
            executed = 0
            for tool_call in result.tool_calls:
                success, _ = self._execute_tool_call_for_thread(tool_call, node.thread_id)
                if success:
                    executed += 1
            
            # æ— æˆåŠŸæ‰§è¡Œæˆ–å·¥å…·ç”¨å®Œï¼Œç»“æŸ
            if executed == 0:
                logger.debug(f"    â†’ æœ¬è½®æ²¡æœ‰æˆåŠŸæ‰§è¡Œä»»ä½•å·¥å…·")
                break
            if not self._has_available_tools(node.tools):
                logger.debug(f"    â†’ æ‰€æœ‰å·¥å…·è°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œ")
                break
        
        logger.debug(f"[DEBUG] å·¥å…·å¾ªç¯å®Œæˆï¼Œå…± {round_count} è½®")
        return result.content if result else ""

    def _llm_single_call(self, node: NodeDefinition, llm) -> str:
        """
        å•æ¬¡ LLM è°ƒç”¨ï¼ˆå¯èƒ½åŒ…å«ä¸€æ¬¡å·¥å…·è°ƒç”¨ï¼‰
        """
        prompt = self._get_prompt(node)
        print("="*20) 
        print(node.node_name)
        print(prompt)
        print("="*20)
        result = llm.invoke(prompt)
        self._accumulate_tokens(result)
        self._add_message_to_thread(node.thread_id, result)
        
        # å¦‚æœæœ‰ tool_callsï¼Œæ‰§è¡Œä¸€æ¬¡
        if hasattr(result, 'tool_calls') and result.tool_calls:
            for tool_call in result.tool_calls:
                self._execute_tool_call_for_thread(tool_call, node.thread_id)
        
        return result.content

    def _execute_llm_first_node(self, node: NodeDefinition) -> str:
        """
        LLM-First èŠ‚ç‚¹æ‰§è¡Œå™¨
        
        æµç¨‹ï¼šLLMæ€è€ƒ -> [å¯é€‰]è°ƒç”¨å·¥å…· -> [å¯é€‰]å¾ªç¯
        
        é…ç½®é€‰é¡¹ï¼š
        - tools: å¯ç”¨å·¥å…·åˆ—è¡¨
        - enable_tool_loop: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨å¾ªç¯
        """
        logger.info(f"æ‰§è¡ŒèŠ‚ç‚¹ [llm-first]: {node.node_name}")
        
        # éªŒè¯å·¥å…·
        if node.tools:
            self._validate_tools(node.tools)
            logger.info(f"    - å¯ç”¨å·¥å…·: {node.tools}")
            logger.info(f"    - å·¥å…·å¾ªç¯: {'å¯ç”¨' if node.enable_tool_loop else 'ç¦ç”¨'}")
        
        # åˆ›å»º LLMï¼ˆå¯èƒ½å¸¦å·¥å…·ï¼‰
        llm = self._create_llm_with_tools(node.tools)
        
        if node.enable_tool_loop and node.tools:
            # å¯ç”¨å¾ªç¯ï¼šä½¿ç”¨ messages åˆ—è¡¨è°ƒç”¨
            final_content = self._llm_tool_loop(node, llm)
        else:
            # ä¸å¯ç”¨å¾ªç¯ï¼šå•æ¬¡è°ƒç”¨
            final_content = self._llm_single_call(node, llm)
        
        # å¤„ç† data_out
        if node.data_out:
            self._set_data_out(node.thread_id, node.node_type, 
                              node.data_out_description, final_content)
        
        return final_content

    def _execute_tool_first_node(self, node: NodeDefinition) -> str:
        """
        Tool-First èŠ‚ç‚¹æ‰§è¡Œå™¨
        
        æµç¨‹ï¼šæ‰§è¡Œåˆå§‹å·¥å…· -> [å¯é€‰]LLMåˆ†æ -> [å¯é€‰]è°ƒç”¨æ›´å¤šå·¥å…· -> [å¯é€‰]å¾ªç¯
        
        é…ç½®é€‰é¡¹ï¼š
        - initial_tool_name: åˆå§‹å·¥å…·åç§°ï¼ˆå¿…éœ€ï¼‰
        - initial_tool_args: åˆå§‹å·¥å…·å‚æ•°
        - task_prompt: LLM ä»»åŠ¡æè¿°ï¼ˆä¸ºç©ºæ—¶åªè¿”å›å·¥å…·ç»“æœï¼‰
        - tools: åç»­å¯ç”¨å·¥å…·åˆ—è¡¨
        - enable_tool_loop: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨å¾ªç¯
        """
        logger.info(f"æ‰§è¡ŒèŠ‚ç‚¹ [tool-first]: {node.node_name}")
        
        # éªŒè¯åˆå§‹å·¥å…·é…ç½®
        if not node.initial_tool_name:
            raise ValueError(f"tool-first èŠ‚ç‚¹ {node.node_name} å¿…é¡»æŒ‡å®š initial_tool_name")
        if node.initial_tool_name not in self.tools_map:
            raise ValueError(f"å·¥å…· {node.initial_tool_name} ä¸å­˜åœ¨")
        
        # æ£€æŸ¥åˆå§‹å·¥å…·è°ƒç”¨é™åˆ¶
        if not self._can_use_tool(node.initial_tool_name):
            error_msg = f"å·¥å…· {node.initial_tool_name} è°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œ"
            logger.info(f"    âœ— {error_msg}")
            self._add_message_to_thread(node.thread_id,
                ToolMessage(content=error_msg, tool_call_id="initial_tool"))
            return error_msg
        
        # æ‰§è¡Œåˆå§‹å·¥å…·
        tool_args = node.initial_tool_args or {}
        logger.info(f"    - æ‰§è¡Œåˆå§‹å·¥å…·: {node.initial_tool_name}")
        logger.info(f"    - å·¥å…·å‚æ•°: {tool_args}")
        tool_result = self.tools_map[node.initial_tool_name].invoke(tool_args)
        self._consume_tool_usage(node.initial_tool_name)
        logger.info(f"    - å·¥å…· {node.initial_tool_name} å‰©ä½™è°ƒç”¨æ¬¡æ•°: {self.tools_usage_limit[node.initial_tool_name]}")
        
        # æ·»åŠ å·¥å…·ç»“æœåˆ°ä¸Šä¸‹æ–‡
        self._add_message_to_thread(node.thread_id,
            ToolMessage(content=str(tool_result), tool_call_id="initial_tool"))
        
        # å¦‚æœæ²¡æœ‰ task_promptï¼Œç›´æ¥è¿”å›å·¥å…·ç»“æœ
        if not node.task_prompt:
            final_content = str(tool_result)
        else:
            # éªŒè¯é¢å¤–å·¥å…·
            if node.tools:
                self._validate_tools(node.tools)
                logger.info(f"    - åç»­å¯ç”¨å·¥å…·: {node.tools}")
                logger.info(f"    - å·¥å…·å¾ªç¯: {'å¯ç”¨' if node.enable_tool_loop else 'ç¦ç”¨'}")
            
            # åˆ›å»º LLMï¼ˆå¯èƒ½å¸¦é¢å¤–å·¥å…·ï¼‰
            llm = self._create_llm_with_tools(node.tools)
            
            if node.enable_tool_loop and node.tools:
                # å¯ç”¨å¾ªç¯
                final_content = self._llm_tool_loop(node, llm)
            else:
                # å•æ¬¡è°ƒç”¨
                final_content = self._llm_single_call(node, llm)
        
        # å¤„ç† data_out
        if node.data_out:
            self._set_data_out(node.thread_id, node.node_type,
                              node.data_out_description, final_content)
        
        return final_content


    def _execute_planning_node(self, node: NodeDefinition) -> str:
        """
        è§„åˆ’èŠ‚ç‚¹ï¼ˆæš‚æœªå®ç°ï¼‰
        
        TODO: åç»­è¿­ä»£å®ç°
        - è°ƒç”¨ LLM ç”Ÿæˆå­è®¡åˆ’ (ä½¿ç”¨ SubExecutorPlan schema)
        - åˆ›å»ºå­çº¿ç¨‹
        - é€’å½’æ‰§è¡Œå­è®¡åˆ’
        - ç»“æœåˆå¹¶
        """
        raise NotImplementedError(
            f"planning èŠ‚ç‚¹ {node.node_name} å°šæœªå®ç°ï¼Œè¯·åœ¨åç»­è¿­ä»£ä¸­æ·»åŠ æ”¯æŒ"
        )

    # =========================================================================
    # ä¸»æ‰§è¡Œæ–¹æ³•
    # =========================================================================
    def execute(self) -> dict:
        """
        æ‰§è¡Œæ•´ä¸ªè®¡åˆ’
        
        Returns:
            dict: åŒ…å«æ‰§è¡Œç»“æœçš„å­—å…¸
                - content: æœ€ç»ˆè¾“å‡ºå†…å®¹
                - messages: æ‰€æœ‰æ¶ˆæ¯ï¼ˆæŒ‰ thread_id ç»„ç»‡ï¼‰
                - tokens_usage: tokens ä½¿ç”¨é‡ç»Ÿè®¡
                - data_out: å„çº¿ç¨‹çš„è¾“å‡ºæ•°æ®
        """
        logger.info(f"\nå¼€å§‹æ‰§è¡Œè®¡åˆ’: {self.plan.task}\n")

        # é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°å’Œ tokens ç»Ÿè®¡
        self.reset_tools_limit()
        self.reset_tokens_usage()

        content = None
        for node in self.plan.nodes:
            # æ ¹æ®èŠ‚ç‚¹é…ç½®é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
            self.reset_tools_limit(node)

            # ç¡®ä¿çº¿ç¨‹å­˜åœ¨
            if node.thread_id not in self.context["messages"]:
                self._create_thread(node.thread_id, node)
            
            # ä½¿ç”¨å¤„ç†å™¨åˆ†å‘
            handler = self._node_handlers.get(node.node_type)
            if not handler:
                raise ValueError(f"æœªçŸ¥èŠ‚ç‚¹ç±»å‹: {node.node_type}")
            
            content = handler(node)
            print(content)
            # å¦‚æœèŠ‚ç‚¹è®¾ç½®äº† data_outï¼Œæ ¹æ® data_out_thread åˆå¹¶åˆ°ç›®æ ‡çº¿ç¨‹
            if node.data_out:
                # ç›®æ ‡çº¿ç¨‹ç”± data_out_thread å†³å®šï¼Œè‹¥æ²¡æœ‰åˆ™é»˜è®¤ä¸º main
                if not node.data_out_thread:
                    logger.warning(f"    âš ï¸  data_out: èŠ‚ç‚¹ '{node.node_name}' æ²¡æœ‰æŒ‡å®š data_out_threadï¼Œä½¿ç”¨é»˜è®¤çš„ main çº¿ç¨‹")
                target_thread = node.data_out_thread if node.data_out_thread else self.main_thread_id
                self._merge_data_out(node.thread_id, target_thread)
        
        logger.info(f"\nè®¡åˆ’æ‰§è¡Œå®Œæˆï¼")
        logger.info(f"ğŸ“Š Tokens ä½¿ç”¨ç»Ÿè®¡:")
        logger.info(f"   - è¾“å…¥ tokens: {self.tokens_usage['input_tokens']}")
        logger.info(f"   - è¾“å‡º tokens: {self.tokens_usage['output_tokens']}")
        logger.info(f"   - æ€»è®¡ tokens: {self.tokens_usage['total_tokens']}\n")
        
        return {
            "content": content,
            "messages": self.context["messages"],
            "tokens_usage": self.tokens_usage,
            "data_out": self.context["data_out"]
        }

# =============================================================================
# æµ‹è¯•ä»£ç 
# =============================================================================
if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•è®¡åˆ’ - ä½¿ç”¨ llm_auto å’Œ query èŠ‚ç‚¹
    #

    # é…ç½®æ—¥å¿—çº§åˆ«ï¼Œæ–¹ä¾¿è°ƒè¯•
    import logging
    logging.basicConfig(
        level=logging.DEBUG,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    import os
    from load_plans import load_plan_from_template
    from langchain_core.tools import tool
    from langchain_openai import ChatOpenAI

    @tool
    def add(a,b):
        "åŠ æ³•"
        return a+b

    tools_map = {
        "add": add
    }

    # åˆ›å»º LLM å·¥å‚å‡½æ•°
    def create_llm_factory():
        """åˆ›å»º LLM å·¥å‚å‡½æ•°"""
        api_key = os.getenv("DASHSCOPE_API_KEY") or os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æˆ– OPENAI_API_KEY")

        return lambda: ChatOpenAI(
            model="qwen-plus-2025-12-01",
            openai_api_key=api_key,
            openai_api_base="https://dashscope.aliyuncs.com/compatible-mode/v1",
            temperature=0.7
        )

    # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    # æ„å»º json æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
    json_path = os.path.join(current_dir, "test_plan", "example", "example.json")
    plan, tools_limit = load_plan_from_template(json_path=json_path,
                                              pattern_name="custom")

    executor = Executor(
        plan,
        "è¯·å¸®æˆ‘æ€»ç»“ 2026-01-03 çš„ä½¿ç”¨æƒ…å†µ",
        tools_map=tools_map,
        default_tools_limit=1,
        llm_factory=create_llm_factory()
    )
    result = executor.execute()

    # æ ¼å¼åŒ–è¾“å‡º
    print("\n" + "=" * 80)
    print("ğŸ“Š AI ç”Ÿæˆçš„è¡Œä¸ºæ€»ç»“")
    print("=" * 80 + "\n")
    print(result["content"])
    print("\n" + "=" * 80)
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯ï¼šå…±äº§ç”Ÿ {sum(len(msgs) for msgs in result['messages'].values())} æ¡æ¶ˆæ¯")
    tokens = result["tokens_usage"]
    print(f"ğŸ”¢ Tokens ä½¿ç”¨: è¾“å…¥={tokens['input_tokens']}, è¾“å‡º={tokens['output_tokens']}, æ€»è®¡={tokens['total_tokens']}")
    print("=" * 80)