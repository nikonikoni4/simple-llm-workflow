# æ‰§è¡Œå™¨å®šä¹‰ V2
# æ”¯æŒå¤šçº¿ç¨‹ Context å’Œ 4 ç§èŠ‚ç‚¹ç±»å‹åˆ†å‘

from lifeprism.llm.llm_classify.tests.data_driving_agent_v2.data_driving_schemas import (
    Context, NodeDefinition, ExecutionPlan, NodeType, ThreadMeta
)
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage
from lifeprism.llm.llm_classify.utils import create_ChatTongyiModel
from lifeprism.llm.llm_classify.tools.database_tools import (
    get_daily_stats,
    get_multi_days_stats,
    query_behavior_logs,
    query_goals,
    query_psychological_assessment
)
from typing import Callable
from lifeprism.utils import get_logger,DEBUG
logger = get_logger(__name__)
class Executor:
    """
    æ•°æ®é©±åŠ¨æ‰§è¡Œå™¨ V2
    
    æ”¯æŒç‰¹æ€§:
    - å¤šçº¿ç¨‹ Context æ¶ˆæ¯éš”ç¦»
    - 4 ç§èŠ‚ç‚¹ç±»å‹åˆ†å‘æ‰§è¡Œ (llm_auto, tool, query, planning)
    - data_out æœºåˆ¶: å­çº¿ç¨‹å‘çˆ¶çº¿ç¨‹è¾“å‡ºç»“æœ
    """
    
    # é»˜è®¤å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
    DEFAULT_TOOLS_USAGE_LIMIT = {
        "get_daily_stats": 1,
        "get_multi_days_stats": 1,
        "query_behavior_logs": 10,
        "query_goals": 1,
        "query_psychological_assessment": 1
    }

    def __init__(
        self, 
        plan: ExecutionPlan, 
        user_message: str, 
        main_thread_id: str = "main",
        tools_limit: dict[str, int] | None = None
    ):
        self.plan = plan
        self.main_thread_id = main_thread_id
        
        # æ–°çš„å¤šçº¿ç¨‹ Context ç»“æ„
        self.context: Context = {
            "messages": {
                main_thread_id: [HumanMessage(content=user_message)]
            },
            "data_out": {},
            "thread_meta": {
                main_thread_id: {"parent_thread": None}
            }
        }
        
        # å·¥å…·æ˜ å°„
        self.tools_map = {
            "get_daily_stats": get_daily_stats,
            "get_multi_days_stats": get_multi_days_stats,
            "query_behavior_logs": query_behavior_logs,
            "query_goals": query_goals,
            "query_psychological_assessment": query_psychological_assessment
        }
        
        # å·¥å…·ä½¿ç”¨é™åˆ¶
        self._initial_tools_limit = self.DEFAULT_TOOLS_USAGE_LIMIT.copy()
        if tools_limit:
            self._initial_tools_limit.update(tools_limit)
        self.tools_usage_limit = self._initial_tools_limit.copy()
        
        # tokens ä½¿ç”¨ç»Ÿè®¡
        self.tokens_usage = {
            'input_tokens': 0,
            'output_tokens': 0,
            'total_tokens': 0
        }
        
        # èŠ‚ç‚¹ç±»å‹ -> å¤„ç†å‡½æ•° æ˜ å°„
        self._node_handlers: dict[NodeType, Callable[[NodeDefinition], str]] = {
            "llm-first": self._execute_llm_first_node,
            "tool-first": self._execute_tool_first_node,
            "planning": self._execute_planning_node,
        }
        self.role_map = {
            "llm-first": "assistant",
            "tool-first": "tool",
            "planning": "assistant"
        }


    # =========================================================================
    # Context è¾…åŠ©æ–¹æ³•
    # =========================================================================
    def _get_thread_messages(self, thread_id: str) -> list:
        """è·å–æŒ‡å®šçº¿ç¨‹çš„æ¶ˆæ¯åˆ—è¡¨"""
        return self.context["messages"].get(thread_id, [])

    def _add_message_to_thread(self, thread_id: str, message) -> None:
        """æ·»åŠ æ¶ˆæ¯åˆ°æŒ‡å®šçº¿ç¨‹"""
        if thread_id not in self.context["messages"]:
            raise ValueError(f"çº¿ç¨‹ {thread_id} ä¸å­˜åœ¨")
        self.context["messages"][thread_id].append(message)

    def _create_thread(self, thread_id: str, parent_thread_id: str | None = None, node: NodeDefinition | None = None) -> None:
        """
        åˆ›å»ºæ–°çº¿ç¨‹ï¼Œå¹¶æ ¹æ® node çš„ data_in é…ç½®æ³¨å…¥åˆå§‹æ¶ˆæ¯
        
        Args:
            thread_id: æ–°çº¿ç¨‹ID
            parent_thread_id: çˆ¶çº¿ç¨‹ID
            node: èŠ‚ç‚¹å®šä¹‰ï¼Œç”¨äºè·å– data_in é…ç½®
        """
        if thread_id in self.context["messages"]:
            return  # çº¿ç¨‹å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        
        self.context["messages"][thread_id] = []
        self.context["thread_meta"][thread_id] = {"parent_thread": parent_thread_id}
        
        # å¤„ç† data_inï¼šæ³¨å…¥åˆå§‹æ¶ˆæ¯åˆ°æ–°çº¿ç¨‹
        if node is not None:
            # ç¡®å®šæ•°æ®æ¥æºçº¿ç¨‹ï¼šä¼˜å…ˆä½¿ç”¨ data_in_threadï¼Œå¦åˆ™ä½¿ç”¨ parent_thread_id
            source_thread = node.data_in_thread or parent_thread_id
            
            if source_thread and source_thread in self.context["messages"]:
                source_msgs = self.context["messages"][source_thread]
                
                # æ£€æŸ¥æºçº¿ç¨‹æ˜¯å¦æœ‰æ•°æ®
                if source_msgs:
                    if node.data_in_slice:
                        # ä½¿ç”¨æŒ‡å®šçš„åˆ‡ç‰‡èŒƒå›´
                        start, end = node.data_in_slice
                        injected = source_msgs[start:end]
                    else:
                        # é»˜è®¤ï¼šå–æœ€åä¸€æ¡æ¶ˆæ¯
                        injected = [source_msgs[-1]]
                    
                    # æ³¨å…¥æ¶ˆæ¯åˆ°æ–°çº¿ç¨‹
                    if injected:
                        self.context["messages"][thread_id].extend(injected)
                        logger.debug(f"    â†’ data_in: ä» '{source_thread}' æ³¨å…¥ {len(injected)} æ¡æ¶ˆæ¯åˆ° '{thread_id}'")

    def _set_data_out(self, thread_id: str, node_type: str, description: str, content: str) -> None:
        """è®¾ç½®çº¿ç¨‹çš„è¾“å‡ºæ•°æ®"""
        self.context["data_out"][thread_id] = {
            "role": self.role_map[node_type],
            "content": f"{description}{content}" if description else content
        }

    def _merge_data_out_to_parent(self, child_thread_id: str) -> None:
        """å°†å­çº¿ç¨‹çš„ data_out åˆå¹¶åˆ°çˆ¶çº¿ç¨‹çš„ messages"""
        if child_thread_id not in self.context["data_out"]:
            return
        
        parent_id = self.context["thread_meta"].get(child_thread_id, {}).get("parent_thread")
        if parent_id and parent_id in self.context["messages"]:
            data = self.context["data_out"][child_thread_id]
            self._add_message_to_thread(parent_id, AIMessage(content=data["content"]))

    # =========================================================================
    # å·¥å…·ç®¡ç†æ–¹æ³•
    # =========================================================================
    def reset_tools_limit(self):
        """é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ä¸ºåˆå§‹é…ç½®"""
        self.tools_usage_limit = self._initial_tools_limit.copy()
    
    def reset_tokens_usage(self):
        """é‡ç½® tokens ä½¿ç”¨ç»Ÿè®¡"""
        self.tokens_usage = {
            'input_tokens': 0,
            'output_tokens': 0,
            'total_tokens': 0
        }
    
    def _accumulate_tokens(self, result) -> None:
        """ç´¯åŠ  tokens ä½¿ç”¨é‡"""
        if hasattr(result, 'response_metadata') and 'token_usage' in result.response_metadata:
            token_usage = result.response_metadata['token_usage']
            self.tokens_usage['input_tokens'] += token_usage.get('input_tokens', 0)
            self.tokens_usage['output_tokens'] += token_usage.get('output_tokens', 0)
            self.tokens_usage['total_tokens'] += token_usage.get('total_tokens', 0)

    def _validate_tools(self, tools: list[str] | None):
        """éªŒè¯å·¥å…·æ˜¯å¦å­˜åœ¨"""
        if not tools:
            return
        for tool in tools:
            if tool not in self.tools_map:
                raise ValueError(f"å·¥å…· {tool} ä¸å­˜åœ¨ï¼Œå¯ç”¨å·¥å…·: {list(self.tools_map.keys())}")

    def _can_use_tool(self, tool_name: str) -> bool:
        """åˆ¤æ–­æŒ‡å®šå·¥å…·æ˜¯å¦è¿˜èƒ½è°ƒç”¨"""
        return self.tools_usage_limit.get(tool_name, 0) > 0
    
    def _consume_tool_usage(self, tool_name: str) -> None:
        """æ¶ˆè€—ä¸€æ¬¡å·¥å…·è°ƒç”¨æ¬¡æ•°"""
        if tool_name in self.tools_usage_limit:
            self.tools_usage_limit[tool_name] -= 1

    def _has_available_tools(self, tools: list[str] | None) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¯ç”¨çš„å·¥å…·è°ƒç”¨æ¬¡æ•°"""
        if not tools:
            return False
        return any(self._can_use_tool(tool) for tool in tools)

    def _tools_limit_prompt(self, tools: list[str] | None) -> str:
        """ç”Ÿæˆå·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶çš„ prompt"""
        if not tools:
            return ""
        lines = []
        for tool in tools:
            remaining = self.tools_usage_limit.get(tool, 0)
            lines.append(f"å·¥å…· {tool} å¯ä»¥è°ƒç”¨ {remaining} æ¬¡")
        return "\n".join(lines)

    def _create_llm_with_tools(self, tools: list[str] | None):
        """åˆ›å»º LLMï¼Œå¦‚æœæœ‰å·¥å…·åˆ™ç»‘å®š"""
        llm = create_ChatTongyiModel(enable_search=False, enable_thinking=False)
        if tools:
            tool_objects = [self.tools_map[t] for t in tools]
            llm = llm.bind_tools(tool_objects)
        return llm

    # =========================================================================
    # Prompt æ„å»º
    # =========================================================================
    def get_history(self, thread_id: str) -> str:
        """è¿”å›æŒ‡å®šçº¿ç¨‹çš„æ ¼å¼åŒ–å†å²æ¶ˆæ¯å­—ç¬¦ä¸²"""
        result = []
        messages = self._get_thread_messages(thread_id)
        for message in messages:
            if isinstance(message, HumanMessage):
                result.append(f"user: {message.content}")
            elif isinstance(message, ToolMessage):
                result.append(f"tool: {message.content}")
            elif isinstance(message, AIMessage):
                # å¦‚æœæœ‰ tool_callsï¼Œéœ€è¦æ ¼å¼åŒ–è¾“å‡º
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    tool_calls_str = ", ".join([
                        f"{tc.get('name', 'unknown')}({tc.get('args', {})})" 
                        for tc in message.tool_calls
                    ])
                    result.append(f"assistant: [è°ƒç”¨å·¥å…·: {tool_calls_str}]")
                    if message.content:
                        result.append(f"assistant: {message.content}")
                else:
                    result.append(f"assistant: {message.content}")
        return "\n".join(result) if result else ""

    def _get_prompt(self, node: NodeDefinition) -> str:
        """æ„å»ºèŠ‚ç‚¹çš„ prompt"""
        tools_limit_prompt = self._tools_limit_prompt(node.tools)
        return f"""
# å†å²æ¶ˆæ¯
{self.get_history(node.thread_id)}
# å·¥å…·å¯è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼Œè¯·åˆç†å®‰æ’å·¥å…·è°ƒç”¨:
{tools_limit_prompt}
# ä½ éœ€è¦æŒ‰ç…§ä¸‹é¢è¦æ±‚å®Œæˆä»»åŠ¡ï¼š
{node.task_prompt}
"""

    # =========================================================================
    # å·¥å…·æ‰§è¡Œ
    # =========================================================================
    def _execute_tool_call_for_thread(self, tool_call: dict, thread_id: str) -> tuple[bool, str | None]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶å°†ç»“æœæ·»åŠ åˆ°æŒ‡å®šçº¿ç¨‹"""
        tool_name = tool_call.get("name", "")
        tool_args = tool_call.get("args", {})
        tool_id = tool_call.get("id", "")
        
        if tool_name not in self.tools_map:
            error_msg = f"æœªçŸ¥å·¥å…·: {tool_name}ï¼Œå¯ç”¨å·¥å…·: {list(self.tools_map.keys())}"
            logger.info(f"    âœ— {error_msg}")
            return False, error_msg
        
        if not self._can_use_tool(tool_name):
            error_msg = f"å·¥å…· {tool_name} è°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œ"
            logger.info(f"    âœ— {error_msg}")
            self._add_message_to_thread(thread_id, ToolMessage(content=error_msg, tool_call_id=tool_id))
            return False, error_msg
        
        logger.info(f"    - æ‰§è¡Œå·¥å…·: {tool_name}, args: {tool_args}")
        tool_result = self.tools_map[tool_name].invoke(tool_args)
        self._consume_tool_usage(tool_name)
        logger.info(f"    - å·¥å…· {tool_name} å‰©ä½™è°ƒç”¨æ¬¡æ•°: {self.tools_usage_limit[tool_name]}")
        
        self._add_message_to_thread(thread_id, ToolMessage(content=str(tool_result), tool_call_id=tool_id))
        return True, str(tool_result)

    # =========================================================================
    # èŠ‚ç‚¹å¤„ç†å™¨
    # =========================================================================
    
    def _llm_tool_loop(self, node: NodeDefinition, llm) -> str:
        """
        LLM å·¥å…·è°ƒç”¨å¾ªç¯
        
        ä½¿ç”¨ messages åˆ—è¡¨è°ƒç”¨ LLMï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨ç›´åˆ° LLM è¿”å›æœ€ç»ˆç»“æœ
        """
        # æ·»åŠ ä»»åŠ¡ prompt åˆ°çº¿ç¨‹
        tools_limit_prompt = self._tools_limit_prompt(node.tools)
        initial_task_prompt = f"""å·¥å…·å¯è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼Œè¯·åˆç†å®‰æ’å·¥å…·è°ƒç”¨:
{tools_limit_prompt}
ä½ éœ€è¦æŒ‰ç…§ä¸‹é¢è¦æ±‚å®Œæˆä»»åŠ¡ï¼š
{node.task_prompt}"""
        self._add_message_to_thread(node.thread_id, HumanMessage(content=initial_task_prompt))
        
        result = None
        round_count = 0
        while True:
            round_count += 1
            logger.debug(f"[DEBUG] ç¬¬ {round_count} è½®å¾ªç¯")
            
            messages = self._get_thread_messages(node.thread_id)
            result = llm.invoke(messages)
            self._accumulate_tokens(result)
            self._add_message_to_thread(node.thread_id, result)
            
            # æ—  tool_callsï¼Œç»“æŸ
            if not (hasattr(result, 'tool_calls') and result.tool_calls):
                logger.debug(f"    â†’ LLM è¿”å›æœ€ç»ˆç»“æœï¼ˆæ—  tool_callsï¼‰")
                break
            
            # æ‰§è¡Œå·¥å…·
            logger.debug(f"    â†’ LLM è¯·æ±‚è°ƒç”¨ {len(result.tool_calls)} ä¸ªå·¥å…·")
            executed = 0
            for tool_call in result.tool_calls:
                success, _ = self._execute_tool_call_for_thread(tool_call, node.thread_id)
                if success:
                    executed += 1
            
            # æ— æˆåŠŸæ‰§è¡Œæˆ–å·¥å…·ç”¨å®Œï¼Œç»“æŸ
            if executed == 0:
                logger.debug(f"    â†’ æœ¬è½®æ²¡æœ‰æˆåŠŸæ‰§è¡Œä»»ä½•å·¥å…·")
                break
            if not self._has_available_tools(node.tools):
                logger.debug(f"    â†’ æ‰€æœ‰å·¥å…·è°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œ")
                break
        
        logger.debug(f"[DEBUG] å·¥å…·å¾ªç¯å®Œæˆï¼Œå…± {round_count} è½®")
        return result.content if result else ""

    def _llm_single_call(self, node: NodeDefinition, llm) -> str:
        """
        å•æ¬¡ LLM è°ƒç”¨ï¼ˆå¯èƒ½åŒ…å«ä¸€æ¬¡å·¥å…·è°ƒç”¨ï¼‰
        """
        prompt = self._get_prompt(node)
        result = llm.invoke(prompt)
        self._accumulate_tokens(result)
        self._add_message_to_thread(node.thread_id, result)
        
        # å¦‚æœæœ‰ tool_callsï¼Œæ‰§è¡Œä¸€æ¬¡
        if hasattr(result, 'tool_calls') and result.tool_calls:
            for tool_call in result.tool_calls:
                self._execute_tool_call_for_thread(tool_call, node.thread_id)
        
        return result.content

    def _execute_llm_first_node(self, node: NodeDefinition) -> str:
        """
        LLM-First èŠ‚ç‚¹æ‰§è¡Œå™¨
        
        æµç¨‹ï¼šLLMæ€è€ƒ -> [å¯é€‰]è°ƒç”¨å·¥å…· -> [å¯é€‰]å¾ªç¯
        
        é…ç½®é€‰é¡¹ï¼š
        - tools: å¯ç”¨å·¥å…·åˆ—è¡¨
        - enable_tool_loop: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨å¾ªç¯
        """
        logger.info(f"æ‰§è¡ŒèŠ‚ç‚¹ [llm-first]: {node.node_name}")
        
        # éªŒè¯å·¥å…·
        if node.tools:
            self._validate_tools(node.tools)
            logger.info(f"    - å¯ç”¨å·¥å…·: {node.tools}")
            logger.info(f"    - å·¥å…·å¾ªç¯: {'å¯ç”¨' if node.enable_tool_loop else 'ç¦ç”¨'}")
        
        # åˆ›å»º LLMï¼ˆå¯èƒ½å¸¦å·¥å…·ï¼‰
        llm = self._create_llm_with_tools(node.tools)
        
        if node.enable_tool_loop and node.tools:
            # å¯ç”¨å¾ªç¯ï¼šä½¿ç”¨ messages åˆ—è¡¨è°ƒç”¨
            final_content = self._llm_tool_loop(node, llm)
        else:
            # ä¸å¯ç”¨å¾ªç¯ï¼šå•æ¬¡è°ƒç”¨
            final_content = self._llm_single_call(node, llm)
        
        # å¤„ç† data_out
        if node.data_out:
            self._set_data_out(node.thread_id, node.node_type, 
                              node.data_out_description, final_content)
        
        return final_content

    def _execute_tool_first_node(self, node: NodeDefinition) -> str:
        """
        Tool-First èŠ‚ç‚¹æ‰§è¡Œå™¨
        
        æµç¨‹ï¼šæ‰§è¡Œåˆå§‹å·¥å…· -> [å¯é€‰]LLMåˆ†æ -> [å¯é€‰]è°ƒç”¨æ›´å¤šå·¥å…· -> [å¯é€‰]å¾ªç¯
        
        é…ç½®é€‰é¡¹ï¼š
        - initial_tool_name: åˆå§‹å·¥å…·åç§°ï¼ˆå¿…éœ€ï¼‰
        - initial_tool_args: åˆå§‹å·¥å…·å‚æ•°
        - task_prompt: LLM ä»»åŠ¡æè¿°ï¼ˆä¸ºç©ºæ—¶åªè¿”å›å·¥å…·ç»“æœï¼‰
        - tools: åç»­å¯ç”¨å·¥å…·åˆ—è¡¨
        - enable_tool_loop: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨å¾ªç¯
        """
        logger.info(f"æ‰§è¡ŒèŠ‚ç‚¹ [tool-first]: {node.node_name}")
        
        # éªŒè¯åˆå§‹å·¥å…·é…ç½®
        if not node.initial_tool_name:
            raise ValueError(f"tool-first èŠ‚ç‚¹ {node.node_name} å¿…é¡»æŒ‡å®š initial_tool_name")
        if node.initial_tool_name not in self.tools_map:
            raise ValueError(f"å·¥å…· {node.initial_tool_name} ä¸å­˜åœ¨")
        
        # æ£€æŸ¥åˆå§‹å·¥å…·è°ƒç”¨é™åˆ¶
        if not self._can_use_tool(node.initial_tool_name):
            error_msg = f"å·¥å…· {node.initial_tool_name} è°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œ"
            logger.info(f"    âœ— {error_msg}")
            self._add_message_to_thread(node.thread_id,
                ToolMessage(content=error_msg, tool_call_id="initial_tool"))
            return error_msg
        
        # æ‰§è¡Œåˆå§‹å·¥å…·
        tool_args = node.initial_tool_args or {}
        logger.info(f"    - æ‰§è¡Œåˆå§‹å·¥å…·: {node.initial_tool_name}")
        logger.info(f"    - å·¥å…·å‚æ•°: {tool_args}")
        tool_result = self.tools_map[node.initial_tool_name].invoke(tool_args)
        self._consume_tool_usage(node.initial_tool_name)
        logger.info(f"    - å·¥å…· {node.initial_tool_name} å‰©ä½™è°ƒç”¨æ¬¡æ•°: {self.tools_usage_limit[node.initial_tool_name]}")
        
        # æ·»åŠ å·¥å…·ç»“æœåˆ°ä¸Šä¸‹æ–‡
        self._add_message_to_thread(node.thread_id,
            ToolMessage(content=str(tool_result), tool_call_id="initial_tool"))
        
        # å¦‚æœæ²¡æœ‰ task_promptï¼Œç›´æ¥è¿”å›å·¥å…·ç»“æœ
        if not node.task_prompt:
            final_content = str(tool_result)
        else:
            # éªŒè¯é¢å¤–å·¥å…·
            if node.tools:
                self._validate_tools(node.tools)
                logger.info(f"    - åç»­å¯ç”¨å·¥å…·: {node.tools}")
                logger.info(f"    - å·¥å…·å¾ªç¯: {'å¯ç”¨' if node.enable_tool_loop else 'ç¦ç”¨'}")
            
            # åˆ›å»º LLMï¼ˆå¯èƒ½å¸¦é¢å¤–å·¥å…·ï¼‰
            llm = self._create_llm_with_tools(node.tools)
            
            if node.enable_tool_loop and node.tools:
                # å¯ç”¨å¾ªç¯
                final_content = self._llm_tool_loop(node, llm)
            else:
                # å•æ¬¡è°ƒç”¨
                final_content = self._llm_single_call(node, llm)
        
        # å¤„ç† data_out
        if node.data_out:
            self._set_data_out(node.thread_id, node.node_type,
                              node.data_out_description, final_content)
        
        return final_content


    def _execute_planning_node(self, node: NodeDefinition) -> str:
        """
        è§„åˆ’èŠ‚ç‚¹ï¼ˆæš‚æœªå®ç°ï¼‰
        
        TODO: åç»­è¿­ä»£å®ç°
        - è°ƒç”¨ LLM ç”Ÿæˆå­è®¡åˆ’ (ä½¿ç”¨ SubExecutorPlan schema)
        - åˆ›å»ºå­çº¿ç¨‹
        - é€’å½’æ‰§è¡Œå­è®¡åˆ’
        - ç»“æœåˆå¹¶
        """
        raise NotImplementedError(
            f"planning èŠ‚ç‚¹ {node.node_name} å°šæœªå®ç°ï¼Œè¯·åœ¨åç»­è¿­ä»£ä¸­æ·»åŠ æ”¯æŒ"
        )

    # =========================================================================
    # ä¸»æ‰§è¡Œæ–¹æ³•
    # =========================================================================
    def execute(self) -> dict:
        """
        æ‰§è¡Œæ•´ä¸ªè®¡åˆ’
        
        Returns:
            dict: åŒ…å«æ‰§è¡Œç»“æœçš„å­—å…¸
                - content: æœ€ç»ˆè¾“å‡ºå†…å®¹
                - messages: æ‰€æœ‰æ¶ˆæ¯ï¼ˆæŒ‰ thread_id ç»„ç»‡ï¼‰
                - tokens_usage: tokens ä½¿ç”¨é‡ç»Ÿè®¡
                - data_out: å„çº¿ç¨‹çš„è¾“å‡ºæ•°æ®
        """
        logger.info(f"\nå¼€å§‹æ‰§è¡Œè®¡åˆ’: {self.plan.task}\n")

        # é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°å’Œ tokens ç»Ÿè®¡
        self.reset_tools_limit()
        self.reset_tokens_usage()

        content = None
        for node in self.plan.nodes:
            # ç¡®ä¿çº¿ç¨‹å­˜åœ¨ï¼Œä½¿ç”¨èŠ‚ç‚¹å®šä¹‰çš„ parent_thread_id
            if node.thread_id not in self.context["messages"]:
                # ä¼˜å…ˆä½¿ç”¨èŠ‚ç‚¹å®šä¹‰çš„ parent_thread_idï¼Œå¦åˆ™é»˜è®¤ä¸º main_thread_id
                parent_id = node.parent_thread_id if node.parent_thread_id else self.main_thread_id
                self._create_thread(node.thread_id, parent_id, node)
            
            # ä½¿ç”¨å¤„ç†å™¨åˆ†å‘
            handler = self._node_handlers.get(node.node_type)
            if not handler:
                raise ValueError(f"æœªçŸ¥èŠ‚ç‚¹ç±»å‹: {node.node_type}")
            
            content = handler(node)
            
            # å¦‚æœèŠ‚ç‚¹è®¾ç½®äº† data_outï¼Œåˆå¹¶åˆ°çˆ¶çº¿ç¨‹
            if node.data_out:
                self._merge_data_out_to_parent(node.thread_id)
        
        logger.info(f"\nè®¡åˆ’æ‰§è¡Œå®Œæˆï¼")
        logger.info(f"ğŸ“Š Tokens ä½¿ç”¨ç»Ÿè®¡: è¾“å…¥={self.tokens_usage['input_tokens']}, "
              f"è¾“å‡º={self.tokens_usage['output_tokens']}, æ€»è®¡={self.tokens_usage['total_tokens']}\n")
        
        return {
            "content": content,
            "messages": self.context["messages"],
            "tokens_usage": self.tokens_usage,
            "data_out": self.context["data_out"]
        }


# =============================================================================
# æµ‹è¯•ä»£ç 
# =============================================================================
if __name__ == "__main__":
    # åˆ›å»ºæµ‹è¯•è®¡åˆ’ - ä½¿ç”¨ llm_auto å’Œ query èŠ‚ç‚¹
    # 
    from lifeprism.llm.llm_classify.tests.data_driving_agent_v2.load_plans import load_plan_from_template
    plan,tools_limit= load_plan_from_template(json_path=r"D:\desktop\è½¯ä»¶å¼€å‘\LifeWatch-AI\lifeprism\llm\llm_classify\tests\data_driving_agent_v2\patterns\test_plan.json",
                        pattern_name="test1",date = "2026-01-03")
    executor = Executor(plan, "è¯·å¸®æˆ‘æ€»ç»“ 2026-01-03 çš„ä½¿ç”¨æƒ…å†µ",tools_limit=tools_limit)
    result = executor.execute()
    
    # æ ¼å¼åŒ–è¾“å‡º
    print("\n" + "=" * 80)
    print("ğŸ“Š AI ç”Ÿæˆçš„è¡Œä¸ºæ€»ç»“")
    print("=" * 80 + "\n")
    print(result["content"])
    print("\n" + "=" * 80)
    print(f"ğŸ“ˆ ç»Ÿè®¡ä¿¡æ¯ï¼šå…±äº§ç”Ÿ {sum(len(msgs) for msgs in result['messages'].values())} æ¡æ¶ˆæ¯")
    tokens = result["tokens_usage"]
    print(f"ğŸ”¢ Tokens ä½¿ç”¨: è¾“å…¥={tokens['input_tokens']}, è¾“å‡º={tokens['output_tokens']}, æ€»è®¡={tokens['total_tokens']}")
    print("=" * 80)