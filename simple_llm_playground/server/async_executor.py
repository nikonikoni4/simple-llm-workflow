# å¼‚æ­¥æ‰§è¡Œå™¨å®šä¹‰ V2
# ç‹¬ç«‹çš„å¼‚æ­¥ç‰ˆæœ¬ï¼Œé€»è¾‘ä¸ŽåŒæ­¥ç‰ˆæœ¬ Executor ç›¸åŒ
# ä¸šåŠ¡æ‰©å±•åº”ç»§æ‰¿æ­¤ç±»

import asyncio
from datetime import datetime
from enum import Enum
from typing import Callable, Optional, Any, Coroutine
from pydantic import BaseModel

from .data_driving_schemas import (
    Context, NodeDefinition, ExecutionPlan, NodeType
)
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

import logging
logger = logging.getLogger(__name__)


# =============================================================================
# æ‰§è¡ŒçŠ¶æ€å®šä¹‰
# =============================================================================
class NodeStatus(str, Enum):
    """èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"


class NodeExecutionState(BaseModel):
    """èŠ‚ç‚¹æ‰§è¡ŒçŠ¶æ€è®°å½•"""
    node_id: int
    node_name: str
    status: NodeStatus = NodeStatus.PENDING
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    error: Optional[str] = None


class NodeContext(BaseModel):
    """èŠ‚ç‚¹ä¸Šä¸‹æ–‡ä¿¡æ¯ - ç”¨äºŽå‰ç«¯å±•ç¤º"""
    node_id: int
    node_name: str
    thread_id: str
    thread_messages_before: list[dict] = []  # æ‰§è¡Œå‰çš„çº¿ç¨‹æ¶ˆæ¯
    thread_messages_after: list[dict] = []   # æ‰§è¡ŒåŽçš„çº¿ç¨‹æ¶ˆæ¯
    llm_input: str = ""                       # LLM è¾“å…¥ prompt
    llm_output: str = ""                      # LLM è¾“å‡º
    tool_calls: list[dict] = []               # å·¥å…·è°ƒç”¨è®°å½•
    data_out_content: Optional[str] = None    # è¾“å‡ºåˆ°çˆ¶çº¿ç¨‹çš„å†…å®¹


# =============================================================================
# å¼‚æ­¥æ‰§è¡Œå™¨
# =============================================================================
class AsyncExecutor:
    """
    å¼‚æ­¥æ•°æ®é©±åŠ¨æ‰§è¡Œå™¨ V2
    
    ç‹¬ç«‹çš„å¼‚æ­¥å®žçŽ°ï¼Œé€»è¾‘ä¸ŽåŒæ­¥ç‰ˆæœ¬ Executor å®Œå…¨ç›¸åŒã€‚
    ä¸šåŠ¡æ‰©å±•ï¼ˆå¦‚è°ƒè¯•æ‰§è¡Œå™¨ï¼‰åº”ç»§æ‰¿æ­¤ç±»ã€‚
    
    æ”¯æŒç‰¹æ€§:
    - å¤šçº¿ç¨‹ Context æ¶ˆæ¯éš”ç¦»
    - 4 ç§èŠ‚ç‚¹ç±»åž‹åˆ†å‘æ‰§è¡Œ (llm-first, tool-first, planning)
    - data_out æœºåˆ¶: å­çº¿ç¨‹å‘çˆ¶çº¿ç¨‹è¾“å‡ºç»“æžœ
    - æ‰§è¡ŒçŠ¶æ€è¿½è¸ª
    - èŠ‚ç‚¹ä¸Šä¸‹æ–‡æ”¶é›†
    """

    def __init__(
        self,
        plan: ExecutionPlan,
        user_message: str,
        main_thread_id: str = "main", # ä¸»çº¿ç¨‹ ID
        tools_map: dict[str, Callable] | None = None, # å·¥å…·æ˜ å°„ {tool_name: callable}
        default_tools_limit: int | None = 1, # é»˜è®¤å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼ˆæ¯ä¸ªå·¥å…·çš„é»˜è®¤è°ƒç”¨æ¬¡æ•°ï¼‰ï¼ŒNone è¡¨ç¤ºæ— é™åˆ¶
        llm_factory: Callable[..., Any] | None = None # LLM å·¥åŽ‚å‡½æ•°ï¼Œç”¨äºŽåˆ›å»º LLM å®žä¾‹
    ):
        """
        åˆå§‹åŒ–å¼‚æ­¥æ‰§è¡Œå™¨

        Args:
            plan: æ‰§è¡Œè®¡åˆ’
            user_message: ç”¨æˆ·æ¶ˆæ¯
            main_thread_id: ä¸»çº¿ç¨‹ ID
            tools_map: å·¥å…·æ˜ å°„ {tool_name: callable}
            default_tools_limit: é»˜è®¤å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼ˆæ¯ä¸ªå·¥å…·çš„é»˜è®¤è°ƒç”¨æ¬¡æ•°ï¼‰ï¼ŒNone è¡¨ç¤ºæ— é™åˆ¶
            llm_factory: LLM å·¥åŽ‚å‡½æ•°ï¼Œç”¨äºŽåˆ›å»º LLM å®žä¾‹
        """
        self.plan = plan
        self.main_thread_id = main_thread_id
        self.llm_factory = llm_factory

        # æ–°çš„å¤šçº¿ç¨‹ Context ç»“æž„
        self.context: Context = {
            "messages": {
                main_thread_id: [HumanMessage(content=user_message)]
            },
            "data_out": {},
        }

        # å·¥å…·æ˜ å°„
        self.tools_map = tools_map or {}

        # é»˜è®¤å·¥å…·ä½¿ç”¨é™åˆ¶ï¼ˆå½“èŠ‚ç‚¹æœªè®¾ç½® tools_limit æ—¶ä½¿ç”¨ï¼‰
        if default_tools_limit:
            self._default_tools_limit = default_tools_limit
        else:
            self._default_tools_limit = 1
        
        self.tools_usage_limit = {}
        
        # tokens ä½¿ç”¨ç»Ÿè®¡
        self.tokens_usage = {
            'input_tokens': 0,
            'output_tokens': 0,
            'total_tokens': 0
        }
        
        # èŠ‚ç‚¹ç±»åž‹ -> å¤„ç†å‡½æ•° æ˜ å°„
        self._node_handlers: dict[NodeType, Callable[[NodeDefinition], Coroutine[Any, Any, str]]] = {
            "llm-first": self._execute_llm_first_node,
            "tool-first": self._execute_tool_first_node,
            "planning": self._execute_planning_node,
        }
        self.role_map = {
            "llm-first": "assistant",
            "tool-first": "tool",
            "planning": "assistant"
        }
        
        # ===== çŠ¶æ€è¿½è¸ªï¼ˆæ–°å¢žï¼‰ =====
        self.node_states: dict[int, NodeExecutionState] = {}
        self.node_contexts: dict[int, NodeContext] = {}
        self._current_node_index = 0  # å½“å‰æ‰§è¡Œåˆ°çš„èŠ‚ç‚¹ç´¢å¼•
        
        # åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€
        self._init_node_states()

    def _init_node_states(self):
        """åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹çš„çŠ¶æ€ä¸º PENDING"""
        for i, node in enumerate(self.plan.nodes):
            node_id = i + 1  # å‡è®¾èŠ‚ç‚¹ ID ä»Ž 1 å¼€å§‹
            self.node_states[node_id] = NodeExecutionState(
                node_id=node_id,
                node_name=node.node_name,
                status=NodeStatus.PENDING
            )
    
    # =========================================================================
    # Context è¾…åŠ©æ–¹æ³•
    # =========================================================================
    def _get_thread_messages(self, thread_id: str) -> list:
        """èŽ·å–æŒ‡å®šçº¿ç¨‹çš„æ¶ˆæ¯åˆ—è¡¨"""
        return self.context["messages"].get(thread_id, [])

    def _add_message_to_thread(self, thread_id: str, message) -> None:
        """æ·»åŠ æ¶ˆæ¯åˆ°æŒ‡å®šçº¿ç¨‹"""
        if thread_id not in self.context["messages"]:
            raise ValueError(f"çº¿ç¨‹ {thread_id} ä¸å­˜åœ¨")
        self.context["messages"][thread_id].append(message)

    def _create_thread(self, thread_id: str, node: NodeDefinition | None = None) -> None:
        """
        åˆ›å»ºæ–°çº¿ç¨‹ï¼Œå¹¶æ ¹æ® node çš„ data_in é…ç½®æ³¨å…¥åˆå§‹æ¶ˆæ¯
        
        Args:
            thread_id: æ–°çº¿ç¨‹ID
            node: èŠ‚ç‚¹å®šä¹‰ï¼Œç”¨äºŽèŽ·å– data_in é…ç½®
        """
        if thread_id in self.context["messages"]:
            return  # çº¿ç¨‹å·²å­˜åœ¨ï¼Œç›´æŽ¥è¿”å›ž
        
        self.context["messages"][thread_id] = []
        # å¤„ç† data_inï¼šæ³¨å…¥åˆå§‹æ¶ˆæ¯åˆ°æ–°çº¿ç¨‹
        if node is not None:
            # ç¡®å®šæ•°æ®æ¥æºçº¿ç¨‹ï¼šä¼˜å…ˆä½¿ç”¨ data_in_threadï¼Œå¦åˆ™é»˜è®¤ä¸º main
            source_thread = node.data_in_thread or self.main_thread_id
            if not node.data_in_thread:
                logger.warning(f"    âš ï¸  data_in: èŠ‚ç‚¹ '{node.node_name}' æ²¡æœ‰æŒ‡å®š data_in_threadï¼Œä½¿ç”¨é»˜è®¤çš„ main çº¿ç¨‹")
            if source_thread and source_thread in self.context["messages"]:
                source_msgs = self.context["messages"][source_thread]
                
                # æ£€æŸ¥æºçº¿ç¨‹æ˜¯å¦æœ‰æ•°æ®
                if source_msgs:
                    if node.data_in_slice:
                        # ä½¿ç”¨æŒ‡å®šçš„åˆ‡ç‰‡èŒƒå›´
                        start, end = node.data_in_slice
                        injected = source_msgs[start:end]
                    else:
                        # é»˜è®¤ï¼šå–æœ€åŽä¸€æ¡æ¶ˆæ¯
                        injected = [source_msgs[-1]]
                    
                    # æ³¨å…¥æ¶ˆæ¯åˆ°æ–°çº¿ç¨‹
                    if injected:
                        self.context["messages"][thread_id].extend(injected)
                        logger.debug(f"    â†’ data_in: ä»Ž '{source_thread}' æ³¨å…¥ {len(injected)} æ¡æ¶ˆæ¯åˆ° '{thread_id}'")

    def _set_data_out(self, thread_id: str, node_type: str, description: str, content: str) -> None:
        """è®¾ç½®çº¿ç¨‹çš„è¾“å‡ºæ•°æ®"""
        self.context["data_out"][thread_id] = {
            "role": self.role_map[node_type],
            "content": f"{description}{content}" if description else content
        }

    def _merge_data_out(self, child_thread_id: str, target_thread_id: str) -> None:
        """
        å°†å­çº¿ç¨‹çš„ data_out åˆå¹¶åˆ°ç›®æ ‡çº¿ç¨‹çš„ messages
        
        Args:
            child_thread_id: å­çº¿ç¨‹IDï¼ˆæ•°æ®æ¥æºï¼‰
            target_thread_id: ç›®æ ‡çº¿ç¨‹IDï¼ˆç”±èŠ‚ç‚¹çš„ data_out_thread å†³å®šï¼‰
        """
        if child_thread_id not in self.context["data_out"]:
            return
        
        if target_thread_id and target_thread_id in self.context["messages"]:
            data = self.context["data_out"][child_thread_id]
            self._add_message_to_thread(target_thread_id, AIMessage(content=data["content"]))
            logger.debug(f"    â†’ data_out: ä»Ž '{child_thread_id}' åˆå¹¶åˆ° '{target_thread_id}'")

    # =========================================================================
    # å·¥å…·ç®¡ç†æ–¹æ³•
    # =========================================================================
    def reset_tools_limit(self, node: NodeDefinition | None = None):
        """
        é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶

        Args:
            node: å½“å‰æ‰§è¡Œçš„èŠ‚ç‚¹ã€‚å¦‚æžœèŠ‚ç‚¹è®¾ç½®äº† tools_limitï¼Œåˆ™ä¸Žé»˜è®¤é™åˆ¶åˆå¹¶ï¼›
                  èŠ‚ç‚¹çš„é™åˆ¶ä¼˜å…ˆçº§é«˜äºŽé»˜è®¤é™åˆ¶ã€‚
        """
        self.tools_usage_limit = {}

        # èŽ·å–å½“å‰èŠ‚ç‚¹ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨
        tools_to_limit = set()
        initial_tool = None
        if node and node.tools:
            tools_to_limit.update(node.tools)
        # å¯¹äºŽ tool-first èŠ‚ç‚¹ï¼Œéœ€è¦åŒ…å«åˆå§‹å·¥å…·ï¼ˆé¢å¤–+1é…é¢ï¼Œå› ä¸ºåˆå§‹è°ƒç”¨ä¸åº”å ç”¨LLMé™é¢ï¼‰
        if node and node.node_type == "tool-first" and node.initial_tool_name:
            initial_tool = node.initial_tool_name
            tools_to_limit.add(initial_tool)

        # åº”ç”¨é»˜è®¤é™åˆ¶åˆ°æ‰€æœ‰ç›¸å…³å·¥å…·
        if self._default_tools_limit is not None:
            for tool in tools_to_limit:
                self.tools_usage_limit[tool] = self._default_tools_limit
            # tool-first çš„åˆå§‹å·¥å…·é¢å¤–+1ï¼ˆåˆå§‹è°ƒç”¨ä¸è®¡å…¥LLMé™é¢ï¼‰
            if initial_tool:
                self.tools_usage_limit[initial_tool] += 1

        # å¦‚æžœèŠ‚ç‚¹æœ‰å•ç‹¬çš„ tools_limitï¼Œè¦†ç›–é»˜è®¤å€¼ï¼ˆä¼˜å…ˆçº§æ›´é«˜ï¼‰
        node_tools_limit = getattr(node, 'tools_limit', None) if node else None
        if node_tools_limit:
            self.tools_usage_limit.update(node_tools_limit)
    
    def reset_tokens_usage(self):
        """é‡ç½® tokens ä½¿ç”¨ç»Ÿè®¡"""
        self.tokens_usage = {
            'input_tokens': 0,
            'output_tokens': 0,
            'total_tokens': 0
        }
    
    def _accumulate_tokens(self, result) -> None:
        """ç´¯åŠ  tokens ä½¿ç”¨é‡"""
        if not result:
            logger.debug("    âš ï¸  _accumulate_tokens: result ä¸ºç©ºï¼Œè·³è¿‡ç»Ÿè®¡")
            return

        tokens_added = False

        # å°è¯•ä»Ž response_metadata èŽ·å– token usage
        if hasattr(result, 'response_metadata') and 'token_usage' in result.response_metadata:
            token_usage = result.response_metadata['token_usage']
            input_tokens = token_usage.get('input_tokens', 0)
            output_tokens = token_usage.get('output_tokens', 0)
            total_tokens = token_usage.get('total_tokens', 0)

            self.tokens_usage['input_tokens'] += input_tokens
            self.tokens_usage['output_tokens'] += output_tokens
            self.tokens_usage['total_tokens'] += total_tokens
            tokens_added = True
            logger.debug(f"    ðŸ“Š Token ç»Ÿè®¡ (response_metadata): input={input_tokens}, output={output_tokens}, total={total_tokens}")

        # å°è¯•ç›´æŽ¥ä»Ž result èŽ·å– token usageï¼ˆæŸäº› LLM å®žçŽ°ï¼‰
        elif hasattr(result, 'token_usage'):
            token_usage = result.token_usage
            input_tokens = token_usage.get('input_tokens', 0)
            output_tokens = token_usage.get('output_tokens', 0)
            total_tokens = token_usage.get('total_tokens', 0)

            self.tokens_usage['input_tokens'] += input_tokens
            self.tokens_usage['output_tokens'] += output_tokens
            self.tokens_usage['total_tokens'] += total_tokens
            tokens_added = True
            logger.debug(f"    ðŸ“Š Token ç»Ÿè®¡ (token_usage): input={input_tokens}, output={output_tokens}, total={total_tokens}")

        # å°è¯•ä»Ž usage_metadata èŽ·å–ï¼ˆOpenAI æ–°ç‰ˆæ ¼å¼ï¼‰
        elif hasattr(result, 'usage_metadata'):
            usage = result.usage_metadata
            input_tokens = usage.get('input_tokens', 0)
            output_tokens = usage.get('output_tokens', 0)
            total_tokens = usage.get('total_tokens', 0)

            self.tokens_usage['input_tokens'] += input_tokens
            self.tokens_usage['output_tokens'] += output_tokens
            self.tokens_usage['total_tokens'] += total_tokens
            tokens_added = True
            logger.debug(f"    ðŸ“Š Token ç»Ÿè®¡ (usage_metadata): input={input_tokens}, output={output_tokens}, total={total_tokens}")

        if not tokens_added:
            logger.warning(f"    âš ï¸  æ— æ³•ä»Ž LLM å“åº”ä¸­èŽ·å– token ç»Ÿè®¡ä¿¡æ¯")
            logger.debug(f"    ðŸ“‹ result ç±»åž‹: {type(result)}, å±žæ€§: {dir(result)}")

    def _validate_tools(self, tools: list[str] | None):
        """éªŒè¯å·¥å…·æ˜¯å¦å­˜åœ¨"""
        if not tools:
            return
        for tool in tools:
            if tool not in self.tools_map:
                raise ValueError(f"å·¥å…· {tool} ä¸å­˜åœ¨ï¼Œå¯ç”¨å·¥å…·: {list(self.tools_map.keys())}")

    def _can_use_tool(self, tool_name: str) -> bool:
        """åˆ¤æ–­æŒ‡å®šå·¥å…·æ˜¯å¦è¿˜èƒ½è°ƒç”¨ï¼ˆæœªå£°æ˜Žçš„å·¥å…·é»˜è®¤æœ‰é»˜è®¤è°ƒç”¨æ¬¡æ•°ï¼‰"""

        return self.tools_usage_limit.get(tool_name, self._default_tools_limit) > 0
   
    
    def _consume_tool_usage(self, tool_name: str) -> None:
        """æ¶ˆè€—ä¸€æ¬¡å·¥å…·è°ƒç”¨æ¬¡æ•°"""
        if tool_name in self.tools_usage_limit:
            self.tools_usage_limit[tool_name] -= 1

    def _has_available_tools(self, tools: list[str] | None) -> bool:
        """æ£€æŸ¥æ˜¯å¦è¿˜æœ‰å¯ç”¨çš„å·¥å…·è°ƒç”¨æ¬¡æ•°"""
        if not tools:
            return False
        return any(self._can_use_tool(tool) for tool in tools)

    def _tools_limit_prompt(self, tools: list[str] | None) -> str:
        """ç”Ÿæˆå·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶çš„ prompt"""
        if not tools:
            return ""
        lines = []
        for tool in tools:
            remaining = self.tools_usage_limit.get(tool, 0)
            lines.append(f"å·¥å…· {tool} å¯ä»¥è°ƒç”¨ {remaining} æ¬¡")
        return "\n".join(lines)

    def _create_llm_with_tools(self, tools: list[str] | None):
        """åˆ›å»º LLMï¼Œå¦‚æžœæœ‰å·¥å…·åˆ™ç»‘å®š"""
        if self.llm_factory is None:
            raise ValueError("å¿…é¡»æä¾› llm_factory æ¥åˆ›å»º LLM å®žä¾‹")
        
        llm = self.llm_factory()
        if tools:
            tool_objects = [self.tools_map[t] for t in tools]
            llm = llm.bind_tools(tool_objects)
        return llm

    # =========================================================================
    # Prompt æž„å»º
    # =========================================================================
    def get_history(self, thread_id: str) -> str:
        """è¿”å›žæŒ‡å®šçº¿ç¨‹çš„æ ¼å¼åŒ–åŽ†å²æ¶ˆæ¯å­—ç¬¦ä¸²"""
        result = []
        messages = self._get_thread_messages(thread_id)
        for message in messages:
            if isinstance(message, HumanMessage):
                result.append(f"user: {message.content}")
            elif isinstance(message, ToolMessage):
                result.append(f"tool: {message.content}")
            elif isinstance(message, AIMessage):
                # å¦‚æžœæœ‰ tool_callsï¼Œéœ€è¦æ ¼å¼åŒ–è¾“å‡º
                if hasattr(message, 'tool_calls') and message.tool_calls:
                    tool_calls_str = ", ".join([
                        f"{tc.get('name', 'unknown')}({tc.get('args', {})})" 
                        for tc in message.tool_calls
                    ])
                    result.append(f"assistant: [è°ƒç”¨å·¥å…·: {tool_calls_str}]")
                    if message.content:
                        result.append(f"assistant: {message.content}")
                else:
                    result.append(f"assistant: {message.content}")
        return "\n".join(result) if result else ""

    def _get_prompt(self, node: NodeDefinition) -> str:
        """æž„å»ºèŠ‚ç‚¹çš„ prompt"""
        return f"""
# åŽ†å²æ¶ˆæ¯
{self.get_history(node.thread_id)}
# ä½ éœ€è¦æŒ‰ç…§ä¸‹é¢è¦æ±‚å®Œæˆä»»åŠ¡ï¼š
{node.task_prompt}
"""

    # =========================================================================
    # æ¶ˆæ¯åºåˆ—åŒ–è¾…åŠ©
    # =========================================================================
    def _serialize_messages(self, messages: list) -> list[dict]:
        """å°†æ¶ˆæ¯åˆ—è¡¨åºåˆ—åŒ–ä¸ºå­—å…¸åˆ—è¡¨ï¼Œç”¨äºŽå‰ç«¯å±•ç¤º"""
        result = []
        for msg in messages:
            if isinstance(msg, HumanMessage):
                result.append({"role": "user", "content": msg.content})
            elif isinstance(msg, AIMessage):
                item = {"role": "assistant", "content": msg.content}
                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                    item["tool_calls"] = msg.tool_calls
                result.append(item)
            elif isinstance(msg, ToolMessage):
                result.append({
                    "role": "tool",
                    "content": msg.content,
                    "tool_call_id": msg.tool_call_id
                })
        return result

    # =========================================================================
    # å·¥å…·æ‰§è¡Œï¼ˆå¼‚æ­¥ï¼‰
    # =========================================================================
    async def _execute_tool_call_for_thread(self, tool_call: dict, thread_id: str) -> tuple[bool, str | None]:
        """æ‰§è¡Œå·¥å…·è°ƒç”¨å¹¶å°†ç»“æžœæ·»åŠ åˆ°æŒ‡å®šçº¿ç¨‹"""
        tool_name = tool_call.get("name", "")
        tool_args = tool_call.get("args", {})
        tool_id = tool_call.get("id", "")
        
        if tool_name not in self.tools_map:
            error_msg = f"æœªçŸ¥å·¥å…·: {tool_name}ï¼Œå¯ç”¨å·¥å…·: {list(self.tools_map.keys())}"
            logger.info(f"    âœ— {error_msg}")
            return False, error_msg
        
        if not self._can_use_tool(tool_name):
            error_msg = f"error å·¥å…· {tool_name} è°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œ"
            logger.info(f"    âœ— {error_msg}")
            self._add_message_to_thread(thread_id, ToolMessage(content=error_msg, tool_call_id=tool_id))
            return False, error_msg
        
        logger.info(f"    - æ‰§è¡Œå·¥å…·: {tool_name}, args: {tool_args}")
        
        # å¼‚æ­¥æ‰§è¡Œå·¥å…·ï¼ˆå¦‚æžœå·¥å…·æ˜¯ coroutineï¼Œä½¿ç”¨ awaitï¼Œå¦åˆ™ç”¨ run_in_executorï¼‰
        tool_func = self.tools_map[tool_name]
        if asyncio.iscoroutinefunction(tool_func.invoke if hasattr(tool_func, 'invoke') else tool_func):
            tool_result = await tool_func.invoke(tool_args)
        else:
            # åŒæ­¥å·¥å…·åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡ž
            loop = asyncio.get_event_loop()
            tool_result = await loop.run_in_executor(None, lambda: tool_func.invoke(tool_args))
        
        self._consume_tool_usage(tool_name)
        logger.info(f"    - å·¥å…· {tool_name} å‰©ä½™è°ƒç”¨æ¬¡æ•°: {self.tools_usage_limit[tool_name]}")
        
        self._add_message_to_thread(thread_id, ToolMessage(content=str(tool_result), tool_call_id=tool_id))
        return True, str(tool_result)

    # =========================================================================
    # èŠ‚ç‚¹å¤„ç†å™¨ï¼ˆå¼‚æ­¥ï¼‰
    # =========================================================================
    
    async def _llm_tool_loop(self, node: NodeDefinition, llm) -> str:
        """
        LLM å·¥å…·è°ƒç”¨å¾ªçŽ¯
        
        ä½¿ç”¨ messages åˆ—è¡¨è°ƒç”¨ LLMï¼Œæ”¯æŒå¤šè½®å·¥å…·è°ƒç”¨ç›´åˆ° LLM è¿”å›žæœ€ç»ˆç»“æžœ
        """
        # æ·»åŠ ä»»åŠ¡ prompt åˆ°çº¿ç¨‹
        tools_limit_prompt = self._tools_limit_prompt(node.tools)
        initial_task_prompt = f"""å·¥å…·å¯è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼Œè¯·åˆç†å®‰æŽ’å·¥å…·è°ƒç”¨:
{tools_limit_prompt}
ä½ éœ€è¦æŒ‰ç…§ä¸‹é¢è¦æ±‚å®Œæˆä»»åŠ¡ï¼š
{node.task_prompt}"""
        self._add_message_to_thread(node.thread_id, HumanMessage(content=initial_task_prompt))
        
        result = None
        round_count = 0
        while True:
            round_count += 1
            logger.debug(f"[DEBUG] ç¬¬ {round_count} è½®å¾ªçŽ¯")
            
            messages = self._get_thread_messages(node.thread_id)
            
            # å¼‚æ­¥è°ƒç”¨ LLM
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, lambda: llm.invoke(messages))
            
            self._accumulate_tokens(result)
            self._add_message_to_thread(node.thread_id, result)
            
            # æ—  tool_callsï¼Œç»“æŸ
            if not (hasattr(result, 'tool_calls') and result.tool_calls):
                logger.debug(f"    â†’ LLM è¿”å›žæœ€ç»ˆç»“æžœï¼ˆæ—  tool_callsï¼‰")
                break
            
            # æ‰§è¡Œå·¥å…·
            logger.debug(f"    â†’ LLM è¯·æ±‚è°ƒç”¨ {len(result.tool_calls)} ä¸ªå·¥å…·")
            executed = 0
            for tool_call in result.tool_calls:
                success, _ = await self._execute_tool_call_for_thread(tool_call, node.thread_id)
                if success:
                    executed += 1
            
            # æ— æˆåŠŸæ‰§è¡Œæˆ–å·¥å…·ç”¨å®Œï¼Œç»“æŸ
            if executed == 0:
                logger.debug(f"    â†’ æœ¬è½®æ²¡æœ‰æˆåŠŸæ‰§è¡Œä»»ä½•å·¥å…·")
                break
            if not self._has_available_tools(node.tools):
                logger.debug(f"    â†’ æ‰€æœ‰å·¥å…·è°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œ")
                break
        
        logger.debug(f"[DEBUG] å·¥å…·å¾ªçŽ¯å®Œæˆï¼Œå…± {round_count} è½®")
        return result.content if result else ""

    async def _llm_single_call(self, node: NodeDefinition, llm) -> str:
        """
        å•æ¬¡ LLM è°ƒç”¨ï¼ˆå¯èƒ½åŒ…å«ä¸€æ¬¡å·¥å…·è°ƒç”¨ï¼‰
        """
        prompt = self._get_prompt(node)
        
        # å¼‚æ­¥è°ƒç”¨ LLM
        loop = asyncio.get_event_loop()
        result = await loop.run_in_executor(None, lambda: llm.invoke(prompt))
        
        self._accumulate_tokens(result)
        self._add_message_to_thread(node.thread_id, result)
        
        # å¦‚æžœæœ‰ tool_callsï¼Œæ‰§è¡Œä¸€æ¬¡
        if hasattr(result, 'tool_calls') and result.tool_calls:
            for tool_call in result.tool_calls:
                await self._execute_tool_call_for_thread(tool_call, node.thread_id)
        
        return result.content

    async def _execute_llm_first_node(self, node: NodeDefinition) -> str:
        """
        LLM-First èŠ‚ç‚¹æ‰§è¡Œå™¨

        æµç¨‹ï¼šLLMæ€è€ƒ -> [å¯é€‰]è°ƒç”¨å·¥å…· -> [å¯é€‰]å¾ªçŽ¯

        é…ç½®é€‰é¡¹ï¼š
        - tools: å¯ç”¨å·¥å…·åˆ—è¡¨
        - enable_tool_loop: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨å¾ªçŽ¯
        - task_prompt: ä¸ºç©ºæ—¶è·³è¿‡ LLM æ‰§è¡Œï¼Œä»…ä½œä¸ºæ•°æ®ä¸­è½¬èŠ‚ç‚¹
        """
        logger.info(f"æ‰§è¡ŒèŠ‚ç‚¹ [llm-first]: {node.node_name}")

        # å¦‚æžœ task_prompt ä¸ºç©ºï¼Œè·³è¿‡ LLM æ‰§è¡Œï¼ˆæ•°æ®ä¸­è½¬èŠ‚ç‚¹ï¼‰
        if not node.task_prompt or node.task_prompt.strip() == "":
            logger.info(f"    - task_prompt ä¸ºç©ºï¼Œè·³è¿‡ LLM æ‰§è¡Œï¼ˆæ•°æ®ä¸­è½¬èŠ‚ç‚¹ï¼‰")
            # å¤„ç† data_outï¿½ï¿½ç©ºå†…å®¹ï¼‰
            if node.data_out:
                self._set_data_out(node.thread_id, node.node_type,
                                  node.data_out_description, "")
            return ""

        # éªŒè¯å·¥å…·
        if node.tools:
            self._validate_tools(node.tools)
            logger.info(f"    - å¯ç”¨å·¥å…·: {node.tools}")
            logger.info(f"    - å·¥å…·å¾ªçŽ¯: {'å¯ç”¨' if node.enable_tool_loop else 'ç¦ç”¨'}")
        
        # åˆ›å»º LLMï¼ˆå¯èƒ½å¸¦å·¥å…·ï¼‰
        llm = self._create_llm_with_tools(node.tools)
        
        if node.enable_tool_loop and node.tools:
            # å¯ç”¨å¾ªçŽ¯ï¼šä½¿ç”¨ messages åˆ—è¡¨è°ƒç”¨
            final_content = await self._llm_tool_loop(node, llm)
        else:
            # ä¸å¯ç”¨å¾ªçŽ¯ï¼šå•æ¬¡è°ƒç”¨
            final_content = await self._llm_single_call(node, llm)
        
        # å¤„ç† data_out
        if node.data_out:
            self._set_data_out(node.thread_id, node.node_type, 
                              node.data_out_description, final_content)
        
        return final_content

    async def _execute_tool_first_node(self, node: NodeDefinition) -> str:
        """
        Tool-First èŠ‚ç‚¹æ‰§è¡Œå™¨
        
        æµç¨‹ï¼šæ‰§è¡Œåˆå§‹å·¥å…· -> [å¯é€‰]LLMåˆ†æž -> [å¯é€‰]è°ƒç”¨æ›´å¤šå·¥å…· -> [å¯é€‰]å¾ªçŽ¯
        
        é…ç½®é€‰é¡¹ï¼š
        - initial_tool_name: åˆå§‹å·¥å…·åç§°ï¼ˆå¿…éœ€ï¼‰
        - initial_tool_args: åˆå§‹å·¥å…·å‚æ•°
        - task_prompt: LLM ä»»åŠ¡æè¿°ï¼ˆä¸ºç©ºæ—¶åªè¿”å›žå·¥å…·ç»“æžœï¼‰
        - tools: åŽç»­å¯ç”¨å·¥å…·åˆ—è¡¨
        - enable_tool_loop: æ˜¯å¦å¯ç”¨å·¥å…·è°ƒç”¨å¾ªçŽ¯
        """
        logger.info(f"æ‰§è¡ŒèŠ‚ç‚¹ [tool-first]: {node.node_name}")
        
        # éªŒè¯åˆå§‹å·¥å…·é…ç½®
        if not node.initial_tool_name:
            raise ValueError(f"tool-first èŠ‚ç‚¹ {node.node_name} å¿…é¡»æŒ‡å®š initial_tool_name")
        if node.initial_tool_name not in self.tools_map:
            raise ValueError(f"å·¥å…· {node.initial_tool_name} ä¸å­˜åœ¨")
        
        # æ£€æŸ¥åˆå§‹å·¥å…·è°ƒç”¨é™åˆ¶
        if not self._can_use_tool(node.initial_tool_name):
            error_msg = f"å·¥å…· {node.initial_tool_name} è°ƒç”¨æ¬¡æ•°å·²ç”¨å®Œ"
            logger.info(f"    âœ— {error_msg}")
            self._add_message_to_thread(node.thread_id,
                ToolMessage(content=error_msg, tool_call_id="initial_tool"))
            return error_msg
        
        # æ‰§è¡Œåˆå§‹å·¥å…·
        tool_args = node.initial_tool_args or {}
        logger.info(f"    - æ‰§è¡Œåˆå§‹å·¥å…·: {node.initial_tool_name}")
        logger.info(f"    - å·¥å…·å‚æ•°: {tool_args}")
        
        # å¼‚æ­¥æ‰§è¡Œåˆå§‹å·¥å…·
        tool_func = self.tools_map[node.initial_tool_name]
        loop = asyncio.get_event_loop()
        if asyncio.iscoroutinefunction(tool_func.invoke if hasattr(tool_func, 'invoke') else tool_func):
            tool_result = await tool_func.invoke(tool_args)
        else:
            tool_result = await loop.run_in_executor(None, lambda: tool_func.invoke(tool_args))
        
        self._consume_tool_usage(node.initial_tool_name)
        logger.info(f"    - å·¥å…· {node.initial_tool_name} å‰©ä½™è°ƒç”¨æ¬¡æ•°: {self.tools_usage_limit[node.initial_tool_name]}")
        
        # æ·»åŠ å·¥å…·ç»“æžœåˆ°ä¸Šä¸‹æ–‡
        self._add_message_to_thread(node.thread_id,
            ToolMessage(content=str(tool_result), tool_call_id="initial_tool"))
        
        # å¦‚æžœæ²¡æœ‰ task_promptï¼Œç›´æŽ¥è¿”å›žå·¥å…·ç»“æžœ
        if not node.task_prompt:
            final_content = str(tool_result)
        else:
            # éªŒè¯é¢å¤–å·¥å…·
            if node.tools:
                self._validate_tools(node.tools)
                logger.info(f"    - åŽç»­å¯ç”¨å·¥å…·: {node.tools}")
                logger.info(f"    - å·¥å…·å¾ªçŽ¯: {'å¯ç”¨' if node.enable_tool_loop else 'ç¦ç”¨'}")
            
            # åˆ›å»º LLMï¼ˆå¯èƒ½å¸¦é¢å¤–å·¥å…·ï¼‰
            llm = self._create_llm_with_tools(node.tools)
            
            if node.enable_tool_loop and node.tools:
                # å¯ç”¨å¾ªçŽ¯
                final_content = await self._llm_tool_loop(node, llm)
            else:
                # å•æ¬¡è°ƒç”¨
                final_content = await self._llm_single_call(node, llm)
        
        # å¤„ç† data_out
        if node.data_out:
            self._set_data_out(node.thread_id, node.node_type,
                              node.data_out_description, final_content)
        
        return final_content


    async def _execute_planning_node(self, node: NodeDefinition) -> str:
        """
        è§„åˆ’èŠ‚ç‚¹ï¼ˆæš‚æœªå®žçŽ°ï¼‰
        
        TODO: åŽç»­è¿­ä»£å®žçŽ°
        - è°ƒç”¨ LLM ç”Ÿæˆå­è®¡åˆ’ (ä½¿ç”¨ SubExecutorPlan schema)
        - åˆ›å»ºå­çº¿ç¨‹
        - é€’å½’æ‰§è¡Œå­è®¡åˆ’
        - ç»“æžœåˆå¹¶
        """
        raise NotImplementedError(
            f"planning èŠ‚ç‚¹ {node.node_name} å°šæœªå®žçŽ°ï¼Œè¯·åœ¨åŽç»­è¿­ä»£ä¸­æ·»åŠ æ”¯æŒ"
        )

    # =========================================================================
    # ä¸»æ‰§è¡Œæ–¹æ³•ï¼ˆå¼‚æ­¥ï¼‰
    # =========================================================================
    async def execute(self) -> dict:
        """
        å¼‚æ­¥æ‰§è¡Œæ•´ä¸ªè®¡åˆ’
        
        Returns:
            dict: åŒ…å«æ‰§è¡Œç»“æžœçš„å­—å…¸
                - content: æœ€ç»ˆè¾“å‡ºå†…å®¹
                - messages: æ‰€æœ‰æ¶ˆæ¯ï¼ˆæŒ‰ thread_id ç»„ç»‡ï¼‰
                - tokens_usage: tokens ä½¿ç”¨é‡ç»Ÿè®¡
                - data_out: å„çº¿ç¨‹çš„è¾“å‡ºæ•°æ®
        """
        logger.info(f"\nå¼€å§‹æ‰§è¡Œè®¡åˆ’: {self.plan.task}\n")

        # é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°å’Œ tokens ç»Ÿè®¡
        self.reset_tools_limit()
        self.reset_tokens_usage()

        content = None
        for i, node in enumerate(self.plan.nodes):
            node_id = i + 1
            # æ ¹æ®èŠ‚ç‚¹é…ç½®é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
            self.reset_tools_limit(node)
            await self._execute_single_node(node, node_id)
            content = self.node_contexts.get(node_id, NodeContext(node_id=node_id, node_name=node.node_name, thread_id=node.thread_id)).llm_output
        
        logger.info(f"\nè®¡åˆ’æ‰§è¡Œå®Œæˆï¼")
        logger.info(f"ðŸ“Š Tokens ä½¿ç”¨ç»Ÿè®¡:")
        logger.info(f"   - è¾“å…¥ tokens: {self.tokens_usage['input_tokens']}")
        logger.info(f"   - è¾“å‡º tokens: {self.tokens_usage['output_tokens']}")
        logger.info(f"   - æ€»è®¡ tokens: {self.tokens_usage['total_tokens']}\n")
        
        return {
            "content": content,
            "messages": self.context["messages"],
            "tokens_usage": self.tokens_usage,
            "data_out": self.context["data_out"]
        }

    async def _execute_single_node(self, node: NodeDefinition, node_id: int) -> str:
        """
        æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            node: èŠ‚ç‚¹å®šä¹‰
            node_id: èŠ‚ç‚¹ ID
            
        Returns:
            èŠ‚ç‚¹æ‰§è¡Œç»“æžœ
        """
        # æ›´æ–°çŠ¶æ€ä¸º RUNNING
        self.node_states[node_id].status = NodeStatus.RUNNING
        self.node_states[node_id].start_time = datetime.now()
        
        # è®°å½•æ‰§è¡Œå‰çš„çº¿ç¨‹æ¶ˆæ¯
        messages_before = self._serialize_messages(
            self._get_thread_messages(node.thread_id)
        )
        
        try:
            # ç¡®ä¿çº¿ç¨‹å­˜åœ¨
            if node.thread_id not in self.context["messages"]:
                self._create_thread(node.thread_id, node)
            
            # ä½¿ç”¨å¤„ç†å™¨åˆ†å‘
            handler = self._node_handlers.get(node.node_type)
            if not handler:
                raise ValueError(f"æœªçŸ¥èŠ‚ç‚¹ç±»åž‹: {node.node_type}")
            
            # è®°å½• LLM è¾“å…¥
            llm_input = self._get_prompt(node)
            
            # æ‰§è¡ŒèŠ‚ç‚¹
            content = await handler(node)
            
            # å¦‚æžœèŠ‚ç‚¹è®¾ç½®äº† data_outï¼Œæ ¹æ® data_out_thread åˆå¹¶åˆ°ç›®æ ‡çº¿ç¨‹
            if node.data_out:
                # ç›®æ ‡çº¿ç¨‹ç”± data_out_thread å†³å®šï¼Œè‹¥æ²¡æœ‰åˆ™é»˜è®¤ä¸º main
                if not node.data_out_thread:
                    logger.warning(f"    âš ï¸  data_out: èŠ‚ç‚¹ '{node.node_name}' æ²¡æœ‰æŒ‡å®š data_out_threadï¼Œä½¿ç”¨é»˜è®¤çš„ main çº¿ç¨‹")
                target_thread = node.data_out_thread if node.data_out_thread else self.main_thread_id
                self._merge_data_out(node.thread_id, target_thread)
            
            # è®°å½•æ‰§è¡ŒåŽçš„çº¿ç¨‹æ¶ˆæ¯
            messages_after = self._serialize_messages(
                self._get_thread_messages(node.thread_id)
            )
            
            # ä¿å­˜èŠ‚ç‚¹ä¸Šä¸‹æ–‡
            self.node_contexts[node_id] = NodeContext(
                node_id=node_id,
                node_name=node.node_name,
                thread_id=node.thread_id,
                thread_messages_before=messages_before,
                thread_messages_after=messages_after,
                llm_input=llm_input,
                llm_output=content,
                tool_calls=[],  # TODO: æ”¶é›†å·¥å…·è°ƒç”¨è®°å½•
                data_out_content=self.context["data_out"].get(node.thread_id, {}).get("content") if node.data_out else None
            )
            
            # æ›´æ–°çŠ¶æ€ä¸º COMPLETED
            self.node_states[node_id].status = NodeStatus.COMPLETED
            self.node_states[node_id].end_time = datetime.now()
            
            self._current_node_index = node_id
            
            return content
            
        except Exception as e:
            # æ›´æ–°çŠ¶æ€ä¸º FAILED
            self.node_states[node_id].status = NodeStatus.FAILED
            self.node_states[node_id].end_time = datetime.now()
            self.node_states[node_id].error = str(e)
            logger.error(f"èŠ‚ç‚¹ {node.node_name} æ‰§è¡Œå¤±è´¥: {e}")
            raise

    async def execute_step(self) -> Optional[NodeContext]:
        """
        å•æ­¥æ‰§è¡Œï¼šæ‰§è¡Œä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œçš„èŠ‚ç‚¹
        
        Returns:
            NodeContext: æ‰§è¡Œå®Œæˆçš„èŠ‚ç‚¹ä¸Šä¸‹æ–‡ï¼Œå¦‚æžœæ²¡æœ‰æ›´å¤šèŠ‚ç‚¹åˆ™è¿”å›ž None
        """
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œçš„èŠ‚ç‚¹
        next_node_id = self._current_node_index + 1
        
        if next_node_id > len(self.plan.nodes):
            logger.info("æ‰€æœ‰èŠ‚ç‚¹å·²æ‰§è¡Œå®Œæˆ")
            return None
        
        # ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶åˆå§‹åŒ–
        if self._current_node_index == 0:
            self.reset_tokens_usage()

        node = self.plan.nodes[next_node_id - 1]
        # æ ¹æ®èŠ‚ç‚¹é…ç½®é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
        self.reset_tools_limit(node)
        await self._execute_single_node(node, next_node_id)
        
        return self.node_contexts.get(next_node_id)

    def get_node_context(self, node_id: int) -> Optional[NodeContext]:
        """èŽ·å–æŒ‡å®šèŠ‚ç‚¹çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        return self.node_contexts.get(node_id)

    def get_all_node_states(self) -> list[NodeExecutionState]:
        """èŽ·å–æ‰€æœ‰èŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€"""
        return list(self.node_states.values())

    def get_execution_progress(self) -> dict:
        """èŽ·å–æ‰§è¡Œè¿›åº¦"""
        total = len(self.plan.nodes)
        completed = sum(1 for s in self.node_states.values() if s.status == NodeStatus.COMPLETED)
        failed = sum(1 for s in self.node_states.values() if s.status == NodeStatus.FAILED)
        running = sum(1 for s in self.node_states.values() if s.status == NodeStatus.RUNNING)
        
        return {
            "total": total,
            "completed": completed,
            "failed": failed,
            "running": running,
            "pending": total - completed - failed - running,
            "progress_percent": (completed / total * 100) if total > 0 else 0
        }
