# å¼‚æ­¥æ‰§è¡Œå™¨å®šä¹‰ V2
# ç‹¬ç«‹çš„å¼‚æ­¥ç‰ˆæœ¬ï¼Œé€»è¾‘ä¸åŒæ­¥ç‰ˆæœ¬ Executor ç›¸åŒ
# ä¸šåŠ¡æ‰©å±•åº”ç»§æ‰¿æ­¤ç±»
import copy
from datetime import datetime
from typing import Callable, Optional, Any
from llm_linear_executor.executor import Executor 
from simple_llm_workflow.schemas import (
    NodeDefinition, ExecutionPlan,NodeStatus,NodeContext,NodeStatus,NodeExecutionState
)
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

import logging
logger = logging.getLogger(__name__)
 


# =============================================================================
# å¼‚æ­¥æ‰§è¡Œå™¨
# =============================================================================
class AsyncExecutor(Executor):
    """
    å¼‚æ­¥æ•°æ®é©±åŠ¨æ‰§è¡Œå™¨ V2
    
    ç»§æ‰¿è‡ª llm_linear_executor.Executorï¼Œæ·»åŠ äº†æ‰§è¡ŒçŠ¶æ€è¿½è¸ªå’Œ execute_step æ”¯æŒã€‚
    """

    def __init__(
        self,
        plan: ExecutionPlan,
        tools_map: dict[str, Callable] | None = None, # å·¥å…·æ˜ å°„ {tool_name: callable}
        default_tools_limit: int | None = 1, # é»˜è®¤å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼ˆæ¯ä¸ªå·¥å…·çš„é»˜è®¤è°ƒç”¨æ¬¡æ•°ï¼‰ï¼ŒNone è¡¨ç¤ºæ— é™åˆ¶
        llm_factory: Callable[..., Any] | None = None # LLM å·¥å‚å‡½æ•°ï¼Œç”¨äºåˆ›å»º LLM å®ä¾‹
    ):
        """
        åˆå§‹åŒ–å¼‚æ­¥æ‰§è¡Œå™¨

        Args:
            plan: æ‰§è¡Œè®¡åˆ’
            tools_map: å·¥å…·æ˜ å°„ {tool_name: callable}
            default_tools_limit: é»˜è®¤å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼ˆæ¯ä¸ªå·¥å…·çš„é»˜è®¤è°ƒç”¨æ¬¡æ•°ï¼‰ï¼ŒNone è¡¨ç¤ºæ— é™åˆ¶
            llm_factory: LLM å·¥å‚å‡½æ•°ï¼Œç”¨äºåˆ›å»º LLM å®ä¾‹
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        # æ³¨æ„ï¼šçˆ¶ç±» __init__ ç­¾åæ˜¯ (plan, tools_map, default_tools_limit, llm_factory)
        super().__init__(
            plan=plan,
            tools_map=tools_map,
            default_tools_limit=default_tools_limit,
            llm_factory=llm_factory
        )
        
        # ===== çŠ¶æ€è¿½è¸ªï¼ˆæ‰©å±•ï¼‰ =====
        self.node_states: dict[int, NodeExecutionState] = {}
        self.node_contexts: dict[int, NodeContext] = {}
        self._current_node_index = 0  # å½“å‰æ‰§è¡Œåˆ°çš„èŠ‚ç‚¹ç´¢å¼•
        
        # ä¸Šä¸‹æ–‡å†å²å¿«ç…§ï¼Œè®°å½•æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œå‰çš„ context
        # ç”¨äºæ”¯æŒèŠ‚ç‚¹é‡æ–°æ‰§è¡Œæ—¶æ¢å¤ä¸Šä¸‹æ–‡
        self.context_history: dict[int, dict] = {}  # {node_id: deepcopy(self.context)}
        
        # åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€
        self._init_node_states()

    def _init_node_states(self):
        """åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹çš„çŠ¶æ€ä¸º PENDING"""
        for i, node in enumerate(self.plan.nodes):
            node_id = i + 1  # å‡è®¾èŠ‚ç‚¹ ID ä» 1 å¼€å§‹
            self.node_states[node_id] = NodeExecutionState(
                node_id=node_id,
                node_name=node.node_name,
                status=NodeStatus.PENDING
            )
    
    # =========================================================================
    # æ¶ˆæ¯åºåˆ—åŒ–è¾…åŠ©
    # =========================================================================
    def _serialize_messages(self, messages: list) -> list[dict]:
        """å°†æ¶ˆæ¯åˆ—è¡¨åºåˆ—åŒ–ä¸ºå­—å…¸åˆ—è¡¨ï¼Œç”¨äºå‰ç«¯å±•ç¤º"""
        result = []
        for msg in messages:
            if isinstance(msg, HumanMessage):
                result.append({"role": "user", "content": msg.content})
            elif isinstance(msg, AIMessage):
                item = {"role": "assistant", "content": msg.content}
                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                    item["tool_calls"] = msg.tool_calls
                result.append(item)
            elif isinstance(msg, ToolMessage):
                result.append({
                    "role": "tool",
                    "content": msg.content,
                    "tool_call_id": msg.tool_call_id
                })
        return result

    # =========================================================================
    # ä¸»æ‰§è¡Œæ–¹æ³•ï¼ˆå¼‚æ­¥ï¼‰- è¦†ç›–çˆ¶ç±» execute (åŒæ­¥)
    # =========================================================================
    async def execute(self) -> dict:
        """
        å¼‚æ­¥æ‰§è¡Œæ•´ä¸ªè®¡åˆ’
        
        Returns:
            dict: åŒ…å«æ‰§è¡Œç»“æœçš„å­—å…¸
                - content: æœ€ç»ˆè¾“å‡ºå†…å®¹
                - messages: æ‰€æœ‰æ¶ˆæ¯ï¼ˆæŒ‰ thread_id ç»„ç»‡ï¼‰
                - tokens_usage: tokens ä½¿ç”¨é‡ç»Ÿè®¡
                - data_out: å„çº¿ç¨‹çš„è¾“å‡ºæ•°æ®
        """
        logger.info(f"\nå¼€å§‹æ‰§è¡Œè®¡åˆ’: {self.plan.task}\n")

        # é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°å’Œ tokens ç»Ÿè®¡
        self.reset_tools_limit()
        self.reset_tokens_usage()

        content = None
        
        # é€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹ï¼Œè¿™é‡Œçš„é€»è¾‘ä¸çˆ¶ç±» aexecute ç±»ä¼¼ï¼Œä½†å¢åŠ äº†çŠ¶æ€æ›´æ–°
        for i, node in enumerate(self.plan.nodes):
            node_id = i + 1
            # æ ¹æ®èŠ‚ç‚¹é…ç½®é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
            self.reset_tools_limit(node)
            await self._execute_single_node(node, node_id)
            context = self.node_contexts.get(node_id)
            if context:
                content = context.llm_output
        
        logger.info(f"\nè®¡åˆ’æ‰§è¡Œå®Œæˆï¼")
        logger.info(f"ğŸ“Š Tokens ä½¿ç”¨ç»Ÿè®¡:")
        logger.info(f"   - è¾“å…¥ tokens: {self.tokens_usage['input_tokens']}")
        logger.info(f"   - è¾“å‡º tokens: {self.tokens_usage['output_tokens']}")
        logger.info(f"   - æ€»è®¡ tokens: {self.tokens_usage['total_tokens']}\n")
        
        return {
            "content": content,
            "messages": self.context["messages"],
            "tokens_usage": self.tokens_usage,
            "data_out": self.context["data_out"]
        }

    async def _execute_single_node(self, node: NodeDefinition, node_id: int) -> str:
        """
        æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            node: èŠ‚ç‚¹å®šä¹‰
            node_id: èŠ‚ç‚¹ ID
            
        Returns:
            èŠ‚ç‚¹æ‰§è¡Œç»“æœ
        """
        # ä¿å­˜æ‰§è¡Œå‰çš„ä¸Šä¸‹æ–‡å¿«ç…§ï¼ˆç”¨äºæ”¯æŒé‡æ–°æ‰§è¡Œï¼‰
        self.context_history[node_id] = copy.deepcopy(self.context)
        
        # æ›´æ–°çŠ¶æ€ä¸º RUNNING
        self.node_states[node_id].status = NodeStatus.RUNNING
        self.node_states[node_id].start_time = datetime.now()
        
        try:
            # ç¡®ä¿çº¿ç¨‹å­˜åœ¨ï¼ˆå¿…é¡»å…ˆåˆ›å»ºçº¿ç¨‹ï¼Œæ‰èƒ½è®°å½•æ¶ˆæ¯ï¼‰
            if node.thread_id not in self.context["messages"]:
                self._create_thread(node.thread_id, node)
            
            # è®°å½•æ‰§è¡Œå‰çš„çº¿ç¨‹æ¶ˆæ¯ï¼ˆåœ¨çº¿ç¨‹ç¡®ä¿å­˜åœ¨åè·å–ï¼‰
            messages_before = self._serialize_messages(
                self._get_thread_messages(node.thread_id)
            )
            
            # ä½¿ç”¨å¤„ç†å™¨åˆ†å‘ (çˆ¶ç±»çš„æ–¹æ³•)
            handler = self._node_handlers.get(node.node_type)
            if not handler:
                raise ValueError(f"æœªçŸ¥èŠ‚ç‚¹ç±»å‹: {node.node_type}")
            
            

            # æ‰§è¡ŒèŠ‚ç‚¹ (ä½¿ç”¨ awaitï¼Œå…¼å®¹çˆ¶ç±»çš„å¼‚æ­¥ handler)
            # å¯¹äº tool-first èŠ‚ç‚¹ï¼Œå·¥å…·è°ƒç”¨å‘ç”Ÿåœ¨ handler å†…éƒ¨
            content = await handler(node)
            # LLM è¾“å…¥ prompt
            llm_input = self._get_prompt(node)
            # åˆ é™¤ prompt ä¸­çš„ å½“å‰èŠ‚ç‚¹çš„è¾“å‡ºcontent
            llm_input = llm_input.replace(content, "")
            
            # å¦‚æœèŠ‚ç‚¹è®¾ç½®äº† data_outï¼Œæ ¹æ® data_out_thread åˆå¹¶åˆ°ç›®æ ‡çº¿ç¨‹
            # (è¿™ä¸ªé€»è¾‘å·²ç»åŒ…å«åœ¨çˆ¶ç±» handler é‡Œäº†å—ï¼Ÿ)
            # æ£€æŸ¥çˆ¶ç±» executor.py:
            # _execute_llm_first_node -> calls _set_data_out.
            # aexecute -> calls _merge_data_out.
            # çˆ¶ç±»çš„ handler åªè´Ÿè´£æ‰§è¡Œå’Œ set_data_outï¼Œmerge æ˜¯ç”±è°ƒç”¨è€…åšçš„ã€‚
            # æ‰€ä»¥è¿™é‡Œéœ€è¦åš mergeã€‚
            
            if node.data_out:
                # ç›®æ ‡çº¿ç¨‹ç”± data_out_thread å†³å®šï¼Œè‹¥æ²¡æœ‰åˆ™é»˜è®¤ä¸º main
                if not node.data_out_thread:
                    logger.warning(f"    âš ï¸  data_out: èŠ‚ç‚¹ '{node.node_name}' æ²¡æœ‰æŒ‡å®š data_out_threadï¼Œä½¿ç”¨é»˜è®¤çš„ main çº¿ç¨‹")
                target_thread = node.data_out_thread if node.data_out_thread else self.main_thread_id
                self._merge_data_out(node.thread_id, target_thread)
            
            # è®°å½•æ‰§è¡Œåçš„çº¿ç¨‹æ¶ˆæ¯
            messages_after = self._serialize_messages(
                self._get_thread_messages(node.thread_id)
            )
            
            # ä¿å­˜èŠ‚ç‚¹ä¸Šä¸‹æ–‡
            self.node_contexts[node_id] = NodeContext(
                node_id=node_id,
                node_name=node.node_name,
                thread_id=node.thread_id,
                thread_messages_before=messages_before,
                thread_messages_after=messages_after,
                llm_input=llm_input,
                llm_output=content,
                tool_calls=[],  # TODO: æ”¶é›†å·¥å…·è°ƒç”¨è®°å½•ï¼Œçˆ¶ç±»ç›®å‰æ²¡æœ‰æ–¹ä¾¿çš„æ¥å£æš´éœ²è¿™ä¸ªï¼Œé™¤éè§£æ messsages
                data_out_content=self.context["data_out"].get(node.thread_id, {}).get("content") if node.data_out else None
            )
            
            # æ›´æ–°çŠ¶æ€ä¸º COMPLETED
            self.node_states[node_id].status = NodeStatus.COMPLETED
            self.node_states[node_id].end_time = datetime.now()
            
            self._current_node_index = node_id
            
            return content
            
        except Exception as e:
            # æ›´æ–°çŠ¶æ€ä¸º FAILED
            self.node_states[node_id].status = NodeStatus.FAILED
            self.node_states[node_id].end_time = datetime.now()
            self.node_states[node_id].error = str(e)
            logger.error(f"èŠ‚ç‚¹ {node.node_name} æ‰§è¡Œå¤±è´¥: {e}")
            raise

    async def execute_step(self) -> Optional[NodeContext]:
        """
        å•æ­¥æ‰§è¡Œï¼šæ‰§è¡Œä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œçš„èŠ‚ç‚¹
        
        Returns:
            NodeContext: æ‰§è¡Œå®Œæˆçš„èŠ‚ç‚¹ä¸Šä¸‹æ–‡ï¼Œå¦‚æœæ²¡æœ‰æ›´å¤šèŠ‚ç‚¹åˆ™è¿”å› None
        """
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œçš„èŠ‚ç‚¹
        next_node_id = self._current_node_index + 1
        
        if next_node_id > len(self.plan.nodes):
            logger.info("æ‰€æœ‰èŠ‚ç‚¹å·²æ‰§è¡Œå®Œæˆ")
            return None
        
        # ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶åˆå§‹åŒ–
        if self._current_node_index == 0:
            self.reset_tokens_usage()

        node = self.plan.nodes[next_node_id - 1]
        # æ ¹æ®èŠ‚ç‚¹é…ç½®é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
        self.reset_tools_limit(node)
        await self._execute_single_node(node, next_node_id)
        
        return self.node_contexts.get(next_node_id)

    def get_node_context(self, node_id: int) -> Optional[NodeContext]:
        """è·å–æŒ‡å®šèŠ‚ç‚¹çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        return self.node_contexts.get(node_id)

    def get_all_node_states(self) -> list[NodeExecutionState]:
        """è·å–æ‰€æœ‰èŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€"""
        return list(self.node_states.values())

    def get_execution_progress(self) -> dict:
        """è·å–æ‰§è¡Œè¿›åº¦"""
        total = len(self.plan.nodes)
        completed = sum(1 for s in self.node_states.values() if s.status == NodeStatus.COMPLETED)
        failed = sum(1 for s in self.node_states.values() if s.status == NodeStatus.FAILED)
        running = sum(1 for s in self.node_states.values() if s.status == NodeStatus.RUNNING)
        
        return {
            "total": total,
            "completed": completed,
            "failed": failed,
            "running": running,
            "pending": total - completed - failed - running,
            "progress_percent": (completed / total * 100) if total > 0 else 0
        }

    async def rerun_node(self, node_id: int) -> Optional[NodeContext]:
        """
        é‡æ–°æ‰§è¡ŒæŒ‡å®šèŠ‚ç‚¹
        
        1. æ¢å¤åˆ°è¯¥èŠ‚ç‚¹æ‰§è¡Œå‰çš„ context
        2. é‡ç½®è¯¥èŠ‚ç‚¹åŠä¹‹åèŠ‚ç‚¹çš„çŠ¶æ€
        3. é‡æ–°æ‰§è¡Œè¯¥èŠ‚ç‚¹
        
        Args:
            node_id: è¦é‡æ–°æ‰§è¡Œçš„èŠ‚ç‚¹ ID
            
        Returns:
            NodeContext: æ‰§è¡Œå®Œæˆçš„èŠ‚ç‚¹ä¸Šä¸‹æ–‡
            
        Raises:
            ValueError: å¦‚æœèŠ‚ç‚¹å°šæœªæ‰§è¡Œè¿‡
        """
        if node_id not in self.context_history:
            raise ValueError(f"èŠ‚ç‚¹ {node_id} å°šæœªæ‰§è¡Œè¿‡ï¼Œæ— æ³•é‡æ–°è¿è¡Œ")
        
        if node_id < 1 or node_id > len(self.plan.nodes):
            raise ValueError(f"èŠ‚ç‚¹ ID {node_id} è¶…å‡ºèŒƒå›´ (1-{len(self.plan.nodes)})")
        
        logger.info(f"ğŸ”„ é‡æ–°æ‰§è¡ŒèŠ‚ç‚¹ {node_id}")
        
        # 1. æ¢å¤ä¸Šä¸‹æ–‡åˆ°è¯¥èŠ‚ç‚¹æ‰§è¡Œå‰çš„çŠ¶æ€
        self.context = copy.deepcopy(self.context_history[node_id])
        
        # 2. åˆ é™¤è¯¥èŠ‚ç‚¹åŠä¹‹åçš„å†å²å’Œä¸Šä¸‹æ–‡
        for nid in list(self.context_history.keys()):
            if nid >= node_id:
                del self.context_history[nid]
        for nid in list(self.node_contexts.keys()):
            if nid >= node_id:
                del self.node_contexts[nid]
        
        # 3. é‡ç½®è¯¥èŠ‚ç‚¹åŠä¹‹åçš„çŠ¶æ€ä¸º PENDING
        for nid, state in self.node_states.items():
            if nid >= node_id:
                state.status = NodeStatus.PENDING
                state.start_time = None
                state.end_time = None
                state.error = None
        
        # 4. æ›´æ–°å½“å‰èŠ‚ç‚¹ç´¢å¼•
        self._current_node_index = node_id - 1
        
        # 5. æ‰§è¡Œè¯¥èŠ‚ç‚¹
        node = self.plan.nodes[node_id - 1]
        self.reset_tools_limit(node)
        await self._execute_single_node(node, node_id)
        
        logger.info(f"âœ… èŠ‚ç‚¹ {node_id} é‡æ–°æ‰§è¡Œå®Œæˆ")
        
        return self.node_contexts.get(node_id)
