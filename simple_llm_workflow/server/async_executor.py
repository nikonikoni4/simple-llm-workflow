# å¼‚æ­¥æ‰§è¡Œå™¨å®šä¹‰ V2
# ç‹¬ç«‹çš„å¼‚æ­¥ç‰ˆæœ¬ï¼Œé€»è¾‘ä¸ŽåŒæ­¥ç‰ˆæœ¬ Executor ç›¸åŒ
# ä¸šåŠ¡æ‰©å±•åº”ç»§æ‰¿æ­¤ç±»
from datetime import datetime
from typing import Callable, Optional, Any
from llm_linear_executor.executor import Executor 
from simple_llm_workflow.schemas import (
    NodeDefinition, ExecutionPlan,NodeStatus,NodeContext,NodeStatus,NodeExecutionState
)
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

import logging
logger = logging.getLogger(__name__)
 


# =============================================================================
# å¼‚æ­¥æ‰§è¡Œå™¨
# =============================================================================
class AsyncExecutor(Executor):
    """
    å¼‚æ­¥æ•°æ®é©±åŠ¨æ‰§è¡Œå™¨ V2
    
    ç»§æ‰¿è‡ª llm_linear_executor.Executorï¼Œæ·»åŠ äº†æ‰§è¡ŒçŠ¶æ€è¿½è¸ªå’Œ execute_step æ”¯æŒã€‚
    """

    def __init__(
        self,
        plan: ExecutionPlan,
        tools_map: dict[str, Callable] | None = None, # å·¥å…·æ˜ å°„ {tool_name: callable}
        default_tools_limit: int | None = 1, # é»˜è®¤å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼ˆæ¯ä¸ªå·¥å…·çš„é»˜è®¤è°ƒç”¨æ¬¡æ•°ï¼‰ï¼ŒNone è¡¨ç¤ºæ— é™åˆ¶
        llm_factory: Callable[..., Any] | None = None # LLM å·¥åŽ‚å‡½æ•°ï¼Œç”¨äºŽåˆ›å»º LLM å®žä¾‹
    ):
        """
        åˆå§‹åŒ–å¼‚æ­¥æ‰§è¡Œå™¨

        Args:
            plan: æ‰§è¡Œè®¡åˆ’
            tools_map: å·¥å…·æ˜ å°„ {tool_name: callable}
            default_tools_limit: é»˜è®¤å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶ï¼ˆæ¯ä¸ªå·¥å…·çš„é»˜è®¤è°ƒç”¨æ¬¡æ•°ï¼‰ï¼ŒNone è¡¨ç¤ºæ— é™åˆ¶
            llm_factory: LLM å·¥åŽ‚å‡½æ•°ï¼Œç”¨äºŽåˆ›å»º LLM å®žä¾‹
        """
        # è°ƒç”¨çˆ¶ç±»åˆå§‹åŒ–
        # æ³¨æ„ï¼šçˆ¶ç±» __init__ ç­¾åæ˜¯ (plan, tools_map, default_tools_limit, llm_factory)
        super().__init__(
            plan=plan,
            tools_map=tools_map,
            default_tools_limit=default_tools_limit,
            llm_factory=llm_factory
        )
        
        # ===== çŠ¶æ€è¿½è¸ªï¼ˆæ‰©å±•ï¼‰ =====
        self.node_states: dict[int, NodeExecutionState] = {}
        self.node_contexts: dict[int, NodeContext] = {}
        self._current_node_index = 0  # å½“å‰æ‰§è¡Œåˆ°çš„èŠ‚ç‚¹ç´¢å¼•
        
        # åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹çŠ¶æ€
        self._init_node_states()

    def _init_node_states(self):
        """åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹çš„çŠ¶æ€ä¸º PENDING"""
        for i, node in enumerate(self.plan.nodes):
            node_id = i + 1  # å‡è®¾èŠ‚ç‚¹ ID ä»Ž 1 å¼€å§‹
            self.node_states[node_id] = NodeExecutionState(
                node_id=node_id,
                node_name=node.node_name,
                status=NodeStatus.PENDING
            )
    
    # =========================================================================
    # æ¶ˆæ¯åºåˆ—åŒ–è¾…åŠ©
    # =========================================================================
    def _serialize_messages(self, messages: list) -> list[dict]:
        """å°†æ¶ˆæ¯åˆ—è¡¨åºåˆ—åŒ–ä¸ºå­—å…¸åˆ—è¡¨ï¼Œç”¨äºŽå‰ç«¯å±•ç¤º"""
        result = []
        for msg in messages:
            if isinstance(msg, HumanMessage):
                result.append({"role": "user", "content": msg.content})
            elif isinstance(msg, AIMessage):
                item = {"role": "assistant", "content": msg.content}
                if hasattr(msg, 'tool_calls') and msg.tool_calls:
                    item["tool_calls"] = msg.tool_calls
                result.append(item)
            elif isinstance(msg, ToolMessage):
                result.append({
                    "role": "tool",
                    "content": msg.content,
                    "tool_call_id": msg.tool_call_id
                })
        return result

    # =========================================================================
    # ä¸»æ‰§è¡Œæ–¹æ³•ï¼ˆå¼‚æ­¥ï¼‰- è¦†ç›–çˆ¶ç±» execute (åŒæ­¥)
    # =========================================================================
    async def execute(self) -> dict:
        """
        å¼‚æ­¥æ‰§è¡Œæ•´ä¸ªè®¡åˆ’
        
        Returns:
            dict: åŒ…å«æ‰§è¡Œç»“æžœçš„å­—å…¸
                - content: æœ€ç»ˆè¾“å‡ºå†…å®¹
                - messages: æ‰€æœ‰æ¶ˆæ¯ï¼ˆæŒ‰ thread_id ç»„ç»‡ï¼‰
                - tokens_usage: tokens ä½¿ç”¨é‡ç»Ÿè®¡
                - data_out: å„çº¿ç¨‹çš„è¾“å‡ºæ•°æ®
        """
        logger.info(f"\nå¼€å§‹æ‰§è¡Œè®¡åˆ’: {self.plan.task}\n")

        # é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°å’Œ tokens ç»Ÿè®¡
        self.reset_tools_limit()
        self.reset_tokens_usage()

        content = None
        
        # é€ä¸ªæ‰§è¡ŒèŠ‚ç‚¹ï¼Œè¿™é‡Œçš„é€»è¾‘ä¸Žçˆ¶ç±» aexecute ç±»ä¼¼ï¼Œä½†å¢žåŠ äº†çŠ¶æ€æ›´æ–°
        for i, node in enumerate(self.plan.nodes):
            node_id = i + 1
            # æ ¹æ®èŠ‚ç‚¹é…ç½®é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
            self.reset_tools_limit(node)
            await self._execute_single_node(node, node_id)
            context = self.node_contexts.get(node_id)
            if context:
                content = context.llm_output
        
        logger.info(f"\nè®¡åˆ’æ‰§è¡Œå®Œæˆï¼")
        logger.info(f"ðŸ“Š Tokens ä½¿ç”¨ç»Ÿè®¡:")
        logger.info(f"   - è¾“å…¥ tokens: {self.tokens_usage['input_tokens']}")
        logger.info(f"   - è¾“å‡º tokens: {self.tokens_usage['output_tokens']}")
        logger.info(f"   - æ€»è®¡ tokens: {self.tokens_usage['total_tokens']}\n")
        
        return {
            "content": content,
            "messages": self.context["messages"],
            "tokens_usage": self.tokens_usage,
            "data_out": self.context["data_out"]
        }

    async def _execute_single_node(self, node: NodeDefinition, node_id: int) -> str:
        """
        æ‰§è¡Œå•ä¸ªèŠ‚ç‚¹ï¼ˆå†…éƒ¨æ–¹æ³•ï¼‰
        
        Args:
            node: èŠ‚ç‚¹å®šä¹‰
            node_id: èŠ‚ç‚¹ ID
            
        Returns:
            èŠ‚ç‚¹æ‰§è¡Œç»“æžœ
        """
        # æ›´æ–°çŠ¶æ€ä¸º RUNNING
        self.node_states[node_id].status = NodeStatus.RUNNING
        self.node_states[node_id].start_time = datetime.now()
        
        try:
            # ç¡®ä¿çº¿ç¨‹å­˜åœ¨ï¼ˆå¿…é¡»å…ˆåˆ›å»ºçº¿ç¨‹ï¼Œæ‰èƒ½è®°å½•æ¶ˆæ¯ï¼‰
            if node.thread_id not in self.context["messages"]:
                self._create_thread(node.thread_id, node)
            
            # è®°å½•æ‰§è¡Œå‰çš„çº¿ç¨‹æ¶ˆæ¯ï¼ˆåœ¨çº¿ç¨‹ç¡®ä¿å­˜åœ¨åŽèŽ·å–ï¼‰
            messages_before = self._serialize_messages(
                self._get_thread_messages(node.thread_id)
            )
            
            # ä½¿ç”¨å¤„ç†å™¨åˆ†å‘ (çˆ¶ç±»çš„æ–¹æ³•)
            handler = self._node_handlers.get(node.node_type)
            if not handler:
                raise ValueError(f"æœªçŸ¥èŠ‚ç‚¹ç±»åž‹: {node.node_type}")
            
            # æ‰§è¡ŒèŠ‚ç‚¹ (ä½¿ç”¨ awaitï¼Œå…¼å®¹çˆ¶ç±»çš„å¼‚æ­¥ handler)
            # å¯¹äºŽ tool-first èŠ‚ç‚¹ï¼Œå·¥å…·è°ƒç”¨å‘ç”Ÿåœ¨ handler å†…éƒ¨
            content = await handler(node)
            
            # åœ¨èŠ‚ç‚¹æ‰§è¡ŒåŽèŽ·å– LLM è¾“å…¥ prompt
            # è¿™æ ·å¯ä»¥ç¡®ä¿ tool-first èŠ‚ç‚¹çš„å·¥å…·è°ƒç”¨ç»“æžœè¢«åŒ…å«åœ¨ prompt ä¸­
            llm_input = self._get_prompt(node)
            
            # å¦‚æžœèŠ‚ç‚¹è®¾ç½®äº† data_outï¼Œæ ¹æ® data_out_thread åˆå¹¶åˆ°ç›®æ ‡çº¿ç¨‹
            # (è¿™ä¸ªé€»è¾‘å·²ç»åŒ…å«åœ¨çˆ¶ç±» handler é‡Œäº†å—ï¼Ÿ)
            # æ£€æŸ¥çˆ¶ç±» executor.py:
            # _execute_llm_first_node -> calls _set_data_out.
            # aexecute -> calls _merge_data_out.
            # çˆ¶ç±»çš„ handler åªè´Ÿè´£æ‰§è¡Œå’Œ set_data_outï¼Œmerge æ˜¯ç”±è°ƒç”¨è€…åšçš„ã€‚
            # æ‰€ä»¥è¿™é‡Œéœ€è¦åš mergeã€‚
            
            if node.data_out:
                # ç›®æ ‡çº¿ç¨‹ç”± data_out_thread å†³å®šï¼Œè‹¥æ²¡æœ‰åˆ™é»˜è®¤ä¸º main
                if not node.data_out_thread:
                    logger.warning(f"    âš ï¸  data_out: èŠ‚ç‚¹ '{node.node_name}' æ²¡æœ‰æŒ‡å®š data_out_threadï¼Œä½¿ç”¨é»˜è®¤çš„ main çº¿ç¨‹")
                target_thread = node.data_out_thread if node.data_out_thread else self.main_thread_id
                self._merge_data_out(node.thread_id, target_thread)
            
            # è®°å½•æ‰§è¡ŒåŽçš„çº¿ç¨‹æ¶ˆæ¯
            messages_after = self._serialize_messages(
                self._get_thread_messages(node.thread_id)
            )
            
            # ä¿å­˜èŠ‚ç‚¹ä¸Šä¸‹æ–‡
            self.node_contexts[node_id] = NodeContext(
                node_id=node_id,
                node_name=node.node_name,
                thread_id=node.thread_id,
                thread_messages_before=messages_before,
                thread_messages_after=messages_after,
                llm_input=llm_input,
                llm_output=content,
                tool_calls=[],  # TODO: æ”¶é›†å·¥å…·è°ƒç”¨è®°å½•ï¼Œçˆ¶ç±»ç›®å‰æ²¡æœ‰æ–¹ä¾¿çš„æŽ¥å£æš´éœ²è¿™ä¸ªï¼Œé™¤éžè§£æž messsages
                data_out_content=self.context["data_out"].get(node.thread_id, {}).get("content") if node.data_out else None
            )
            
            # æ›´æ–°çŠ¶æ€ä¸º COMPLETED
            self.node_states[node_id].status = NodeStatus.COMPLETED
            self.node_states[node_id].end_time = datetime.now()
            
            self._current_node_index = node_id
            
            return content
            
        except Exception as e:
            # æ›´æ–°çŠ¶æ€ä¸º FAILED
            self.node_states[node_id].status = NodeStatus.FAILED
            self.node_states[node_id].end_time = datetime.now()
            self.node_states[node_id].error = str(e)
            logger.error(f"èŠ‚ç‚¹ {node.node_name} æ‰§è¡Œå¤±è´¥: {e}")
            raise

    async def execute_step(self) -> Optional[NodeContext]:
        """
        å•æ­¥æ‰§è¡Œï¼šæ‰§è¡Œä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œçš„èŠ‚ç‚¹
        
        Returns:
            NodeContext: æ‰§è¡Œå®Œæˆçš„èŠ‚ç‚¹ä¸Šä¸‹æ–‡ï¼Œå¦‚æžœæ²¡æœ‰æ›´å¤šèŠ‚ç‚¹åˆ™è¿”å›ž None
        """
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªå¾…æ‰§è¡Œçš„èŠ‚ç‚¹
        next_node_id = self._current_node_index + 1
        
        if next_node_id > len(self.plan.nodes):
            logger.info("æ‰€æœ‰èŠ‚ç‚¹å·²æ‰§è¡Œå®Œæˆ")
            return None
        
        # ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶åˆå§‹åŒ–
        if self._current_node_index == 0:
            self.reset_tokens_usage()

        node = self.plan.nodes[next_node_id - 1]
        # æ ¹æ®èŠ‚ç‚¹é…ç½®é‡ç½®å·¥å…·è°ƒç”¨æ¬¡æ•°é™åˆ¶
        self.reset_tools_limit(node)
        await self._execute_single_node(node, next_node_id)
        
        return self.node_contexts.get(next_node_id)

    def get_node_context(self, node_id: int) -> Optional[NodeContext]:
        """èŽ·å–æŒ‡å®šèŠ‚ç‚¹çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        return self.node_contexts.get(node_id)

    def get_all_node_states(self) -> list[NodeExecutionState]:
        """èŽ·å–æ‰€æœ‰èŠ‚ç‚¹çš„æ‰§è¡ŒçŠ¶æ€"""
        return list(self.node_states.values())

    def get_execution_progress(self) -> dict:
        """èŽ·å–æ‰§è¡Œè¿›åº¦"""
        total = len(self.plan.nodes)
        completed = sum(1 for s in self.node_states.values() if s.status == NodeStatus.COMPLETED)
        failed = sum(1 for s in self.node_states.values() if s.status == NodeStatus.FAILED)
        running = sum(1 for s in self.node_states.values() if s.status == NodeStatus.RUNNING)
        
        return {
            "total": total,
            "completed": completed,
            "failed": failed,
            "running": running,
            "pending": total - completed - failed - running,
            "progress_percent": (completed / total * 100) if total > 0 else 0
        }
